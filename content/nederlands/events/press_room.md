---
title: Nieuws
subtitle: >
  Persberichten van Stichting Algorithm Audit. Kom in contact met de organisatie
  door [dit](/nl/about/contact/) contactformulier in te vullen.
image: /images/svg-illustrations/about.svg
quick_navigation:
  title: Overzicht
  links:
    - title: Brouwer Vertrouwensprijs
      url: '#KHMW'
    - title: DUO2 Addendum Vooringenomenheid voorkomen
      url: '#DUO_CBS'
    - title: DUO1 Vooringenomenheid voorkomen
      url: '#DUO'
    - title: Onderzoek Rotterdam
      url: '#Rotterdam'
---

<!-- KHMW -->

{{< accordions_area_open id="KHWM">}}

{{< accordion_item_open title="Algorithm Audit wint Brouwer Vertrouwensprijs van €100.000" id="KHMW" background_color="#ffffff" date="19-01-2026" tag1="KHMW" tag2="Brouwer Vertrouwensprijs" image="/images/partner logo-cropped/KHMW.png" >}}

<b>DEN HAAG – Algorithm Audit viert feest: maandag 19 januari mochten we de eerste prijs van de KHMW Brouwer Vertrouwensprijzen 2026 in ontvangst nemen. Deze prijs is een belangrijke mijlpaal voor onze stichting en een erkenning van de maatschappelijke relevantie van ons werk.</b>

Met de <a href="https://khmw.nl" target="_blank">Brouwer Vertrouwensprijzen</a> stimuleert de Koninklijke Hollandsche Maatschappij der Wetenschappen (KHMW) maatschappelijke initiatieven die het onderling vertrouwen in de Nederlandse samenleving versterken. Dit jaar gaat de eerste prijs (€100.000) naar stichting Algorithm Audit. Mede dankzij deze prijs kunnen we de komende jaren meer casusonderzoek doen en zo bijdragen aan de verantwoorde inzet van AI. Directeur Jurriaan Parie in een <a href="https://khmw.nl/winnaar-eerste-prijs-khmw-brouwer-vertrouwensprijzen-2026-algorithm-audit/" target="_blank">interview</a> met de KHMW: ‘Zeggenschap over technologie geeft grip, en grip vergroot vertrouwen. Dankzij de Brouwer Vertrouwensprijs kunnen wij onze maatschappelijke ambities blijven nastreven'.

#### Lof van de jury
De jury benadrukte tijdens uitreiking van de Vertouwensprijs in Haarlem dat “Algorithm Audit een enorm actueel onderwerp aanpakt en zij een belangrijk tegenwicht vormt aan de opkomende macht van techbedrijven en AI en ook aan de ongelijke machtsverhouding die er nu vaak bestaat tussen overheid en burger”. De jury sprak hierbij de hoop uit “dat toenemende bekendheid en kracht van Algorithm Audit ook zal leiden tot een meer zelfregulerende houding van de betreffende bedrijven en instanties, waarbij door zelfkritisch hun eigen algoritmes te evalueren en indien nodig aan te passen zij ook een meer geloofwaardiger partner worden van burgers en klanten”.

#### Meebelissen over de inzet van algoritmes en AI
Het winnen van deze prijs voelt als de kroon op ons werk van de afgelopen jaren. Sinds de oprichting in 2021 zet stichting Algorithm Audit zich in om burgers en belanghebbenden een stem te geven in de manier waarop algoritmes en AI worden ingezet. De stichting brengt onafhankelijke adviescommissies bijeen waarin wetenschappelijke experts en burgervertegenwoordigers samen concrete AI-toepassingen beoordelen. 

Deze werkwijze, die wij ‘algoprudentie’ noemen, zorgt ervoor dat we als samenleving op een transparante en democratische wijze kunnen meedenken over de toekomst van deze cruciale technologie. Jurriaan Parie: ‘We willen burgers en het maatschappelijk middenveld een stem geven in de manier waarop technologie wordt ingezet, door overheden én bedrijven. Technologie beïnvloedt steeds meer ons dagelijks leven. De vraag is: hoeveel grip hebben we daarop, en wie kan daarover meepraten?’
In de afgelopen jaren onderzocht Algorithm Audit onder meerdere risicoprofileringsalgoritmen bij gemeenten, bij de uitvoeringsorganisatie Dienst Uitvoering Onderwijs (DUO) en een platform voor leenauto’s. Dat leidde tot concrete adviezen aan overheden, publieke verantwoording en aantoonbare verbeteringen in beleid en uitvoering. De tools die we ontwikkelen om datagedreven toepassingen te onderzoeken stellen we open source beschikbaar zodat iedereen ze kan gebruiken om bijvoorbeeld discriminatie op te sporen.

#### Onze plannen
Met het prijzengeld kunnen we de organisatie versterken en ons werkterrein uitbreiden. We willen ons de komende jaren verder verdiepen in generatieve AI. Met de opkomst van chatbots die steeds vaker tussen overheid en burger, en tussen consument en bedrijven komen te staan, gaan risico’s gepaard. Daar zijn nieuwe evaluatiemethoden voor nodig: geven dit soort informatiesystemen betrouwbare informatie, zijn ze daadwerkelijk effectief en verwijzen chatbots adequaat door naar menselijke medewerkers? 

De komende tijd gaan we hete hangijzers identificeren en casussen uitwerken. Onze algoprudentie voegt maatschappelijke waarde toe doordat de stem van een diverse groep van belanghebbende wordt vastgelegd en publiekelijk wordt gedeeld. Door kennis te delen en belanghebbenden samen te brengen, willen we bijdragen aan een samenleving waarin technologie het onderlinge vertrouwen versterkt in plaats van ondermijnt.

#### Meer over Algorithm Audit
Algorithm Audit is een kennisplatform voor verantwoorde AI. De stichting brengt expertise samen op het raakvlak van techniek, recht en ethiek. Als groeiend nationaal en Europees kennisplatform delen we onze expertise via onderzoek, whitepapers, workshops en lezingen. Algorithm Audit is een onafhankelijke stichting en verricht zijn activiteiten zonder winstoogmerk.

{{< accordion_item_close >}}


<!-- DUO 2 -->

{{< accordion_item_open title="Controleproces DUO vooringenomen voor studenten met een niet-Europese migratieachtergrond" id="DUO_CBS" background_color="#ffffff" date="22-05-2024" tag1="DUO" tag2="CBS" tag3="bias analyse" image="/images/partner logo-cropped/DUO.png" >}}

**DEN HAAG – In de controle op rechtmatig gebruik van studiefinanciering
voor uitwonende studenten controleerde DUO aanzienlijk vaker studenten met een niet-Europese
migratieachtergrond. Hieruit blijkt een onbewuste vooringenomenheid van het
controleproces van DUO. Studenten met een niet-Europese migratieachtergrond
kregen een hogere risicoscore toegekend door een risicoprofiel en werden vaker handmatig
geselecteerd voor een huisbezoek. Dit blijkt uit vervolgonderzoek dat stichting
Algorithm Audit heeft uitgevoerd in opdracht van DUO en op 22 mei door de
minister aan de Tweede Kamer is verstuurd. De onderzoeksresultaten versterken
het beeld van eerder onderzoek, op basis waarvan de minister op 1 maart 2024 namens
het kabinet zijn excuses heeft aangeboden voor indirecte discriminatie in het
controleproces.**

DUO verzocht Algorithm Audit om
vervolgonderzoek te doen op basis van gedetailleerde data die het CBS heeft
verstrekt over de herkomst van meer dan 300.000 studenten in de periode
2014-2022. Deze data maakt mogelijk om de vooringenomenheid van het controleproces
precies te meten. De vooringenomenheid betekent dat er een oververtegenwoordiging
van studenten met een niet-Europese migratieachtergrond ontstaat als
(onbedoeld) effect van de wijze waarop het controleproces is opgezet.

Het onderzoek stelt vast dat de vooringenomenheid ontstaat in
verschillende stappen van het controleproces. Zowel door het gebruikte
risicoprofiel als de handmatige selectie daarna werden studenten met een
niet-Europese migratieachtergrond vaker geselecteerd voor controle. Ook al speelde
de herkomst van studenten geen directe rol in het controleproces van DUO, er
ontstaat een indirecte vooringenomenheid als gevolg van de criteria waarop werd
geselecteerd.

Bepaalde kenmerken (waaronder de onderwijsvorm mbo 1-2 en een kleine
afstand tot het ouderlijk adres) leidden tot een verhoogde risicoscore. En
omdat deze kenmerken vaker voorkomen onder studenten met een niet-Europese
migratieachtergrond, ontstond een oververtegenwoordiging van deze groep. Ook
andere kenmerken speelden een rol in de beslissing of een student werd
geselecteerd voor controle, waaronder inschrijving bij familie of juist in een
studentenhuis. Het effect van al deze factoren was een vergrootglaseffect waardoor
DUO vooral bij studenten met een niet-Europese migratieachtergrond onrechtmatigheid
opspoorde. Onrechtmatig gebruik van de studiebeurs door studenten zonder
migratieachtergrond bleef juist vaker buiten beeld.

Data-analyse van Algorithm Audit laat zien dat studenten met een
niet-Europese migratieachtergrond 2.0x vaker als hoog risico werden gezien door
het risicoprofiel dan studenten zonder migratieachtergrond. De groep werd 6.2x
vaker handmatig geselecteerd voor een huisbezoek. Uiteindelijk hadden studenten
met een niet-Europese migratieachtergrond een 3.0x grotere kans om onterecht
een huisbezoek te krijgen dan studenten met een Nederlandse herkomst.

Uit het onderzoek treedt voor de periode 2014-2022 een consistent beeld
naar voren dat de groep van studenten die in bezwaar ging tegen een besluit van
DUO vooral uit studenten met een niet-Europese migratieachtergrond bestaat. Dit
bevestigt het beeld uit [berichtgeving](https://nos.nl/op3/video/2479701-zo-checkt-duo-of-jij-fraudeert-en-dat-systeem-rammelt) van Investico
en NOS in 2023, dat studenten met een migratieachtergrond vaker dan andere
studenten werden beschuldigd van onrechtmatig gebruik van studiefinanciering en
daarvoor in bezwaar gingen. Eerder onderzoek van PwC bracht op basis van
postcodestatistieken aan het licht dat studenten die staan ingeschreven in
migrantenwijken vaker door DUO werden gecontroleerd. De resultaten van het
vervolgonderzoek van Algorithm Audit laten een versterkte vooringenomenheid
zien ten opzichte van eerdere onderzoeken. Zowel de CBS-data en de door
Algorithm Audit gebruikte onderzoeksmethoden zijn publiek toegankelijk ([hier](https://www.cbs.nl/nl-nl/maatwerk/2024/21/ontvangers-uitwonendenbeurs-herkomst-2014-2017-2019-2021-en-2022) en hier te vinden).

DUO heeft het normale controleproces
voor de uitwonendenbeurs momenteel stopgezet en selecteert studenten alleen
willekeurig. DUO en Algorithm Audit blijven samenwerken om de resultaten van de
onderzoeken samen met verschillende maatschappelijke belanghebbenden te
interpreteren en na te denken over verbeteringen in een mogelijk toekomstig controleproces.

Het rapport Vooringenomenheid
voorkomen (addendum) kan [hier](/nl/algoprudence/cases/aa202402_bias-prevented_addendum/) worden gevonden.

{{< accordion_item_close >}}

<!-- DUO 1 -->

{{< accordion_item_open title="Afwijkingen geconstateerd in controleproces DUO naar misbruik met uitwonendenbeurs" id="DUO" background_color="#ffffff" date="01-03-2024" tag1="DUO" image="/images/partner logo-cropped/DUO.png" tag2="audit rapport" >}}

<b>DEN HAAG – DUO selecteerde in onderzoek naar misbruik met de uitwonendenbeurs aanzienlijk
vaker studenten die dicht bij hun ouder(s) woonden. Het algoritme dat ter ondersteuning van
de selectie werd gebruikt functioneerde naar verwachting. De combinatie van het
algoritme en handmatige selectie zorgde echter voor een grote oververtegenwoordiging
van bepaalde groepen. Geselecteerde studenten werden thuis
bezocht om te controleren of zij geen misbruik maakten. Dit is de belangrijkste conclusie van het
onderzoek dat Stichting Algorithm Audit uitvoert in opdracht van DUO. Het controleproces van DUO kwam in 2023 in opspraak na <a href="https://nos.nl/op3/video/2479701-zo-checkt-duo-of-jij-fraudeert-en-dat-systeem-rammelt" target="_blank">berichtgeving</a> van Investico en NOS, waarin werd vermeld dat studenten met een migratieachtergrond vaker dan andere studenten werden beschuldigd van misbruik.</b>

Studenten die dicht bij hun ouder(s) stonden ingeschreven zijn aanzienlijk
vaker geselecteerd voor een huisbezoek. DUO beslist naar aanleiding van dergelijke
controles of er misbruik is gemaakt van de uitwonendenbeurs. Deze afwijkijking is
veel groter dan wanneer uitsluitend het regel-gebaseerde algoritme zou zijn gevolgd
dat de Dienst Uitvoering Onderwijs (‘DUO’) gebruikte om in de periode 2012-2022
aan alle uitwonende studenten (ruim 500.000) een risicoscore toe te kennen. Voor
de hand ligt dat specifieke werkinstructies – die aansporen tot het handmatig
selecteren van studenten die nabij het ouderlijk adres staan ingeschreven –
hier de oorzaak van zijn. Dat is de belangrijkste conclusie van het rapport Vooringenomenheid
voorkomen van Stichting Algorithm Audit dat op 1 maart 2024 naar de Tweede
Kamer is gestuurd. 

Uit het onderzoek volgt verder onvoldoende
statistisch verband tussen een aantal selectiecriteria die in het door DUO
gehanteerde risicotaxatie-algoritme zijn gebruikt (te weten onderwijsvorm en
leeftijd). Voor het selectiecriterium afstand tot ouder(s) is wel statistisch
bewijs voor een verband met onrechtmatigheid gevonden. Deze resultaten zijn
gebaseerd op een statistische analyse van misbruikcontrole op basis van aselecte
steekproeven uit 2014 en 2017. Ook stelt Stichting Algorithm Audit vast dat het
gebruikte algoritme niet voldoet aan de eisen die op dit moment worden gesteld
aan door de Nederlandse overheid gebruikte algoritmes. Op verzoek van DUO is
aan deze nieuwste normen voor het gebruik van algoritmes door de overheid
getoetst. Zo ontbreekt er een gedegen onderbouwing van keuzes die tijdens het ontwerp
van het algoritme zijn gemaakt. Daarnaast is niet gebleken van onderzoek naar
mogelijke indirecte vooringenomenheid van het gebruikte algoritme, noch bij het
opstellen, noch bij het gebruik ervan.

In opdracht van DUO doet de Stichting
Algorithm Audit onafhankelijk onderzoek naar het controleproces
uitwonendenbeurs. Aanleiding is dat studenten met een migratieachtergrond vaker
worden <a href="https://nos.nl/op3/video/2479701-zo-checkt-duo-of-jij-fraudeert-en-dat-systeem-rammelt" target="_blank">beschuldigd</a>
van misbruik met studiefinanciering. Of de groep die bovenmatig vaak is
geselecteerd voor een huisbezoek inderdaad ook bovenmatig vaak een
migratieachtergrond heeft zal blijken uit vervolgonderzoek dat op dit moment
wordt uitgevoerd. Hierbij gebruikt Stichting Algorithm Audit data die zijn
opgevraagd bij het Centraal Bureau voor de Statistiek (CBS) om het percentage
studenten per herkomstland te meten gedurende het gehele controleproces. Publiek
toegankelijk data – zoals migratiestatistieken per postcodegebied of de gemiddelde
afstand die bepaalde demografische groepen tot hun ouder(s) wonen – is volgens Stichting
Algorithm Audit te onnauwkeurig om voor dit gevoelige onderzoek te gebruiken.
Het is wat Stichting Algorithm Audit dan ook te vroeg om te kunnen concluderen
of studenten met een migratieachtergrond inderdaad benadeeld zijn, al is van
het tegendeel in het onderzoek ook niet gebleken. Stichting Algorithm Audit stelt
wel vast dat er niet is gebleken van directe discriminatie op basis van
migratieachtergrond in het algoritme.

De uitkomsten van de onderzoeken worden gebruikt om te
bepalen of risicoprofilering in de toekomst verantwoord kan worden ingezet om
misbruik met de uitwonendenbeurs op te sporen. Dit is relevant aangezien de
uitwonendenbeurs sinds dit studiejaar is geherintroduceerd voor studenten die
op kamers wonen en een hogere beroepsopleiding of wetenschappelijke opleiding
volgen. DUO en Stichting Algorithm Audit blijven in 2024 samenwerken om de
resultaten van de onderzoeken samen met verschillende maatschappelijke belanghebbenden
te interpreteren. Momenteel selecteert DUO studenten alleen willekeurig voor
controle.

Het volledige rapport *Vooringenomenheid voorkomen* (AA:2024:01) kan [hier](https://algorithmaudit.eu/nl/algoprudence/cases/aa202401_bias-prevented/) worden gevonden.

01-03-2024

{{< accordion_item_close >}}

<!-- Rotterdam case -->

{{< accordion_item_open title="Onafhankelijke commissie publiceert advies aan gemeenten voor risicoprofilering in de bijstand" id="Rotterdam" background_color="#ffffff" date="29-11-2023" image="/images/logo/logo.svg" tag1="gemeente Rotterdam" tag2="algoprudentie" tag3="machine learning" >}}

**DEN HAAG – Staatssecretaris Alexandra van Huffelen heeft op 29 november het [adviesrapport](/algoprudence/cases/risk-profiling-for-social-welfare-reexamination-aa202302/) aangenomen met daarin concrete normen voor de verantwoorde inzet van algoritmes. Stichting Algorithm Audit stelde een onafhankelijke commissie samen van experts die advies uitbrengt om oneerlijke behandeling te voorkomen bij bijstandsheronderzoek. De aanleiding voor het opstellen van het advies is het controversiële risicomodel dat gebruikt is door de Gemeente Rotterdam tot 2021.**

Wanneer de gemeente onderzoekt of bijstandsgerechtigden nog wel recht hebben op bijstand wordt soms gebruik gemaakt van algoritmische profilering. Het adviesrapport, opgesteld door vertegenwoordigers van de Ombudsman van Amsterdam en Rotterdam, verschillende academici, en een wethouder uit Tilburg, adviseert dat onder andere postcode, het aantal kinderen en laaggeletterdheid niet meer als kenmerk gebruikt mag worden voor profilering. Eerder is gebleken dat profilering in de context van de bijstand kan leiden tot discriminatie. De onafhankelijke commissie stelt dat er ook andere ethische bezwaren kleven aan algoritmische profilering. Sommige zelflerende algoritmes zijn namelijk te ingewikkeld om de beslissingen nog goed aan de burger te kunnen uitleggen. De commissie adviseert daarom om bepaalde algoritmes niet meer te gebruiken.

Het advies is gericht aan alle 340 Nederlandse gemeenten. Het advies vormt een onderdeel van de ‘algoprudentie’ die Stichting Algorithm Audit ontwikkelt om samen met experts en diverse belangengroepen tot concrete normen te komen voor de verantwoorde inzet van algoritmes. Stichting Algorithm Audit is een onafhankelijk kennisplatform voor ethische algoritmes en AI en wordt ondersteund door het European AI\&Society Fund, het SIDN fonds en het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties.

{{< image id="presentatie" width_desktop="6" width_mobile="12" image1="/images/algoprudence/AA202302/Algorithm audit presentatie BZK FB-18.jpg" alt1="Presentatie Staatssecretaris voor Digitalisering" caption1="Presentatie Staatssecretaris voor Digitalisering" >}}

29-11-2023

{{< container_close >}}
