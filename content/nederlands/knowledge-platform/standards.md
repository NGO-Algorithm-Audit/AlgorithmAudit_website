---
title: 'Standaarden voor AI '
subtitle: >
  Verantwoorde inzet van AI zal niet worden opgelost door technische standaarden
  alleen. Om te bepalen wat de 'verantwoorde inzet' inhoudt is collectieve
  deliberatie vereist met diverse belanghebbenden. Door actief bij te dragen aan
  discussies bij nationale en Europese standaardiseringsorganisaties (NEN en
  CEN), draagt Algorithm Audit bij aan het vormgeven van procedurele standaarden
  waarbij verschillende belanghebbende worden betrokken om AI vorm te geven.
image: /images/svg-illustrations/case_repository.svg
team:
  title: AI standaarden team
  icon: fas fa-user-friends
  button_text: Andere teams
  id: team
  button_link: /nl/about/teams/
  team_members:
    - image: /images/people/EPetersen.jpeg
      name: Eike Petersen
      bio: |
        Post-doc Fair AI in Medicine, Technical University of Denmark
    - image: /images/people/JParie.jpg
      name: Jurriaan Parie
      bio: |
        Directeur-bestuurder
---

{{< container_open icon="fas fa-check" title="AI Act standaarden" id="ai-act" >}}

In 2023 hebben de Europese standaardiseringsorganisaties CEN en CENELEC het verzoek van de Europese Commissie geaccepteerd om standaarden te ontwikkelen voor Artificiële Intelligentie (AI). Joint Technical Committee 21 (JTC21) van CEN-CENELEC is momenteel bezig Europese standaarden voor AI te ontwikkelen, zoals standaarden voor risicomanagement, datakwaliteit en procedurele standaarden voor het testen van vooringenomenheid. Als  AI-ontwikkelaars en -gebruikers zich aan deze standaarden houden wordt naleving van de aanstaande AI Verordening verondersteld. Maar zo ver is het nog niet. Het ontwikkelen van standaarden is momenteel volop aan de gang. Als lid van het Nederlands Normaliseringsinstituut (NEN) draagt Algorithm Audit bij aan het Europese debat over de vorm deze AI standaarden aannemen, en in hoeverre technische standaarden ontwikkeld kunnen worden voor aan fundamentele rechten rakende standaarden, zoals non-discriminatie, menselijke tussenkomst en uitlegbaarheid van algoritme-gedreven besluitvorming. Dit doen wij door deel te nemen aan de volgende werkgroepen:

* WG2 – Risicomanagement (risk management systems)
* WG3 – Technische aspects (engineering aspects)
* WG4 – Verantwoorde AI (trustworthy AI).

Tijdens de laatste plenaire bijeenkomst van JTC21 in Dublin 12-14 februari presenteerde Algorithm Audit onderaan bijgevoegde slides over Fundamentele Rechten Impact Assessments (FRIAs) voor AI en de noodzaak voor inclusieve, deliberatieve adviescommissies om verantwoorde AI in te zetten.

{{< image id="standaarden" width_desktop="3" width_mobile="6" image1="/images/partners/NEN.svg" alt1="Stichting Koninklijk Nederlands Normalisatie Instituut" caption1="Stichting Koninklijk Nederlands Normalisatie Instituut" image2="/images/partners/CEN.jpg" alt2="European Committee for Standardization" caption2="European Committee for Standardization" >}}

{{< pdf_frame articleUrl1="https://drive.google.com/file/d/1vadydN4_ZEXJ0h_Sj-4GRUwJSacM0fCK/preview" width_desktop_pdf="12" width_mobile_pdf="12" >}}

{{< container_close >}}

{{< container_open icon="fas fa-ruler" title="Standaarden" id="AI-standaarden" >}}

Het standaardiseringsverzoek van de Europese Commissie, dat een uitgangsbasis biedt voor naleving van de AI Verordening, relateert aan de volgende tien aspecten:

1. Risicomanagementsysteem voor AI-systemen
2. Organisatorische omgang met data en datakwaliteitvereisten om AI-systemen te bouwen
3. Data-administratieve middels het loggen van AI-systemen
4. Transparantie- en informatieverplichtingen voor gebruikers van AI-systemen
5. Menselijk toezicht op AI-systemen
6. Nauwkeurigheidspecificaties voor AI-systemen
7. Robuustheidspecificaties voor AI-systemen
8. Cybersecurity-specificaties voor AI-systemen
9. Kwaliteitsmanagementsystemen voor aanbieders van AI-systemen, inclusief monitoringsprocesses na te zijn geïntroduceerd op de markt
10. Conformiteitsbeoordeling van AI-systemen.

In de audits van Algorithm Audit worden alle bovenstaande aspecten meegenomen, met uitzondering van 8. Cybersecurity-specificaties voor AI-systemen. Organisaties kunnen leren van onze technische en normatieve algoritme audits die [publiek toegankelijk](/nl/algoprudence/) zijn. Het volledige standaardiseringsverzoek van de Europese Commissie kan [hier](https://single-market-economy.ec.europa.eu/single-market/european-standards/standardisation-requests_en) worden gevonden.

{{< button button_text="Bespreek samenwerking" button_link="/nl/knowledge-platform/collaboration/" >}}

{{< container_close >}}

{{< team >}}
