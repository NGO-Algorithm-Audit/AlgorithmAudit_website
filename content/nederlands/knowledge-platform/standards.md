---
title: 'Standaarden voor AI-systemen'
subtitle: >
  Verantwoorde inzet van AI zal niet worden opgelost door technische standaarden
  alleen. Om te bepalen wat de 'verantwoorde inzet' inhoudt is collectieve
  deliberatie vereist met diverse belanghebbenden. Door actief bij te dragen aan
  discussies bij nationale en Europese standaardiseringsorganisaties (NEN en
  CEN), draagt Algorithm Audit bij aan het vormgeven van procedurele standaarden
  waarbij verschillende belanghebbende worden betrokken om AI vorm te geven.
image: /images/svg-illustrations/case_repository.svg
team:
  title: Team AI-verordening geharmoniseerde normen
  icon: fas fa-user-friends
  button_text: Andere teams
  id: team
  button_link: /nl/about/teams/
  team_members:
    - image: /images/people/JParie.jpg
      name: Jurriaan Parie
      bio: |
        Director and board member, Algorithm Audit
    - image: /images/people/YRemmits.jpg
      name: Ylja Remmits
      bio: |
        Head of Projects, Algorithm Audit
quick_navigation:
  title: Inhoudsopgave
  links:
    - title: Introductie
      url: '#standardization-request'
    - title: AI-verordening geharmoniseerde normen
      url: '#standards'
    - title: Bijdragen
      url: '#contributions'
    - title: Team
      url: '#team'
---

{{< container_open icon="fas fa-check" title="AI-verordening geharmoniseerde normen" id="standardization-request" >}}

In 2023 hebben de Europese standaardiseringsorganisaties CEN en CENELEC het verzoek van de Europese Commissie geaccepteerd om standaarden te ontwikkelen voor Artificiële Intelligentie (AI). Joint Technical Committee 21 (JTC21) van CEN-CENELEC is momenteel bezig Europese standaarden voor AI te ontwikkelen, zoals standaarden voor risicomanagement, datakwaliteit en procedurele standaarden voor het testen van vooringenomenheid. Als  AI-ontwikkelaars en -gebruikers zich aan deze standaarden houden wordt naleving van de aanstaande AI Verordening verondersteld. Maar zo ver is het nog niet. Het ontwikkelen van standaarden is momenteel volop aan de gang. Als lid van het Nederlands Normaliseringsinstituut (NEN) draagt Algorithm Audit bij aan het Europese debat over de vorm deze AI standaarden aannemen, en in hoeverre technische standaarden ontwikkeld kunnen worden voor aan fundamentele rechten rakende standaarden, zoals non-discriminatie, menselijke tussenkomst en uitlegbaarheid van algoritme-gedreven besluitvorming. Dit doen wij door deel te nemen aan de volgende werkgroepen:

* WG2 – Risicomanagement (risk management systems)
* WG3 – Technische aspects (engineering aspects)
* WG4 – Verantwoorde AI (trustworthy AI).

Tijdens de laatste plenaire bijeenkomst van JTC21 in Dublin 12-14 februari presenteerde Algorithm Audit onderaan bijgevoegde slides over Fundamentele Rechten Impact Assessments (FRIAs) voor AI en de noodzaak voor inclusieve, deliberatieve adviescommissies om verantwoorde AI in te zetten.

{{< image id="standaarden" width_desktop="3" width_mobile="6" image1="/images/partner logo-cropped/NEN.svg" alt1="Stichting Koninklijk Nederlands Normalisatie Instituut" caption1="Stichting Koninklijk Nederlands Normalisatie Instituut" image2="/images/partner logo-cropped/CEN.jpg" alt2="European Committee for Standardization" caption2="European Committee for Standardization" >}}

{{< container_close >}}

{{< container_open icon="fas fa-ruler" title="AI-verordening geharmoniseerde normen" id="standards" >}}

Het standaardiseringsverzoek van de Europese Commissie, dat een uitgangsbasis biedt voor naleving van de AI Verordening, relateert aan de volgende tien aspecten:

1. Risicomanagementsysteem voor AI-systemen
2. Organisatorische omgang met data en datakwaliteitvereisten om AI-systemen te bouwen
3. Data-administratieve middels het loggen van AI-systemen
4. Transparantie- en informatieverplichtingen voor gebruikers van AI-systemen
5. Menselijk toezicht op AI-systemen
6. Nauwkeurigheidspecificaties voor AI-systemen
7. Robuustheidspecificaties voor AI-systemen
8. Cybersecurity-specificaties voor AI-systemen
9. Kwaliteitsmanagementsystemen voor aanbieders van AI-systemen, inclusief monitoringsprocesses na te zijn geïntroduceerd op de markt
10. Conformiteitsbeoordeling van AI-systemen.

In de audits van Algorithm Audit worden alle bovenstaande aspecten meegenomen, met uitzondering van 8. Cybersecurity-specificaties voor AI-systemen. Organisaties kunnen leren van onze technische en normatieve algoritme audits die [publiek toegankelijk](/nl/algoprudence/) zijn. Het volledige standaardiseringsverzoek van de Europese Commissie kan [hier](https://single-market-economy.ec.europa.eu/single-market/european-standards/standardisation-requests_en) worden gevonden.

{{< button button_text="Bespreek samenwerking" button_link="/nl/knowledge-platform/collaboration/" >}}

{{< container_close >}}

{{< container_open icon="fas fa-file" title="Bijdragen" id="contributions" >}}

Selectie van bijdragen aan normcommissie JTC21 van CEN-CENELEC.

#### Statistische hypothese toest als risicobeheersmaatregel

{{< embed_pdf url="/pdf-files/knowledge-base/standards/20240726_AlgorithmAudit_statistical_hypothesis_testing.pdf" width_desktop_pdf="12" width_mobile_pdf="12">}}

#### Fundamental Rights Impact Assessment (FRIA) and stakeholder panels

{{< embed_pdf url="/pdf-files/knowledge-base/standards/20240213_JTC21_plenary_FRIAs_stakeholder_panels.pdf" width_desktop_pdf="12" width_mobile_pdf="12">}}

{{< container_close >}}

{{< team id="team">}}
