---
title: >-
  Bias rapport Kort Verblijf Visum – SigmaRed in opdracht van het Ministerie van
  Buitenlandse Zaken
subtitle: >
  Bias test van het Ministerie van Buitenlandse Zaken kort verblijf visum
  classificatie model door SigmaRed Technologies. Het rapport concludeert dat er
  geen disproportionele discriminatie plaatsvindt op basis van leeftijd,
  burgerlijke staat en gender. Essentiële stappen in het valideren van
  selectiecriteria ontbreken echter, welke essentieel zijn om dergelijke
  conclusies te kunnen trekken.
image: /images/knowledge_base/BuZa_SR.png
author: SigmaRed
type: regular
summary: >-
  Bias assessment of Dutch Ministry of Ministry of Foreign Affairs' short stay
  visa classification model by SigmaRed Technologies
---

Volledige rapport: [https://www.tweedekamer.nl/kamerstukken/detail?id=2024D17777\&did=2024D17777](https://www.tweedekamer.nl/kamerstukken/detail?id=2024D17777\&did=2024D17777)

#### Bias rapport Kort Verblijf Visum – SigmaRed in opdracht van het Ministerie van Buitenlandse Zaken

Bias rapport op verzoek van het Ministerie van Buitenlandse Zaken over het Kort Verblijf Visum (KVV) proces waarin een regel-gebaseerd classificatiemodel wordt gebruikt om aanvragers in te delen in een snelle, reguliere of intensieve aanvraagprocedures. Het doel van het rapport is om "potentiële bias op te sporen en te wegen door de relatie tussen risicoprofielpercentages en afwijzingspercentages tussen verschillende demografische groepen te onderzoeken".

Op basis van een vergelijking tussen disparate impact ratios tussen 2022 en 2023 wordt geconcludeerd dat er "geen onevenredige discriminatie op basis van leeftijd, burgerlijke staat of geslacht" wordt gevonden\*. In het rapport wordt voor veel biasmetrieken gemotiveerd waarom deze niet gebruikt worden. Echter ontbreekt deze verklaring voor de bias metriek conditionele demografische pariteit (CDP). Het is algemeen <a href="https://arxiv.org/abs/2005.05906" target="_blank">bekend</a> dat CDP de voorkeur geniet boven DI, omdat het beter bestand is tegen Simpson's paradox. De auteurs motiveren echter niet waarom van dit voorkeursscenario wordt afgeweken. Het gebruik van CDP als  biasmetriek kan leiden tot andere kwantitatieve uitkomsten die de huidige conclusie van het rapport mogelijk niet ondersteunen. 

Daarnaast staat het rapport niet stil bij de geschiktheid van de criteria op basis waarvan het risicoprofiel onderscheid maakt. De volgende 7 criteria worden in het profiel gebruikt:

1. Verblijfsdoel
2. Post (plaats van aanvraag)
3. Nationaliteit
4. Geslacht
5. Leeftijdsklasse
6. Burgetlijke staat
7. Beroep.

Alvorens zulke criteria rechtmatig gebruikt kunnen worden in een risicoprofiel dient te moeten worden gemotiveerd waarom differentiatie op basis van deze criteria is proportioneel, geschikt en noodzakelijk is. <a href="https://publicaties.mensenrechten.nl/publicatie/61a734e65d726f72c45f9dce" target="_blank">Kaders</a> van het College van de Rechten van de Mensen maken deze verplichting concreet. Bijvoorbeeld, kwantitatief bewijs voor het gerbuiken van selectiecriteria in een risicoprofiel kan worden gevonden door statistische hypothesetoetsen uit te voeren op willekeurig getrokken steekproeven van visa-aanvragers. Het is onduidelijk waarom deze triviale eerste stap in het toetsen van een risicoprofiel niet wordt behandeld in dit rapport. 

Voor leeftijdsdiscriminatie licht het College van de Rechten van de Mens toe:

> "\[...] het is niet per se verboden dat een algoritme iemands leeftijd meeneemt. Toch zal er wel een duidelijk verband moet zijn tussen leeftijd en het doel van het algoritme. Zolang niet is aangetoond dat iemands leeftijd de kans vergroot op \[het weigeren van een visumaanvraag] mag je leeftijd evengoed niet laten meewegen in de algoritmische selectie."

Het is dus opmerkelijk dat de conclusie (dat het algoritme niet discrimineert op basis van leeftijd) enkel op kwanitatieve resultaten is gebaseerd.

In general, the socio-technological nature of algorithmic-driven decision-making processes is overlooked in this bias assessment. It is crucial to recognise that mitigating algorithmic bias requires attention of both the quantitative and qualitative reasoning paradigm, not only including numbers but also fostering organisational checks and balances, and a safe working environment that promotes open discussion about data-driven decision-making.

Lastly, instead of using advanced causal inference techniques such as inverse probability weighting (IPW) and instrument variable (IV) analysis to assess whether the rule-based classification model had a direct effect on the decisions made by officers, a preference is given to the simpler F-test.

\* for visa applicants with the Yemeni nationality a certain degree of unequal treatment is reported	&#x9;
