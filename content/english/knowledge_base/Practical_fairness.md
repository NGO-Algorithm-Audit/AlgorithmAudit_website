---
title: Practical Fairness
author: Aileen Nielsen
image: /images/knowledge_base/practical_fairness.jpeg
type: featured
summary: A wide-ranging book that informs data and AI ethics practitioners about recent advances in open-source toolkits and legal frameworks.

---
###### **Author: Aileen Nielsen**

How to make fairness tangible? Don’t take the philosophical route, use practical legal and technological frameworks to assess fairness – that’s the adage of this book. Hands-on experience with coding machine learning and statistics might be useful to digest the discussed topics. 

Fairness is examined in three main domains: 1) Anti-discrimination, 2) Security and 3) Privacy. Although most attention regarding fairness is (as expected) absorbed by anti-discrimination, the book advocates convincingly why security and privacy should be part of the fairness equation. “What do we think about stealing someone’s time and subverting their autonomy?” Indeed, social media platforms and apps written for smart homes can be considered as fairness problems too. By linking anti-discrimination to security and privacy, this work is a broad guidebook to define notions of fairness for the digital future.

The book starts with raising three fundamental, pragmatic, and unavoidable questions about fairness: 

<span style="color:#005aa7; font-weight: bold;">1\.</span> What is equity? _Equality of opportunity_ or _equality of outcome_?

<span style="color:#005aa7; font-weight: bold;">2\.</span> Should decisions be uniform or embody an element of human empathy? _Impartial justice_ or _individual allowances_?

<span style="color:#005aa7; font-weight: bold;">3\.</span> Is it fairer to let people know how decisions are made or to have an opaque system to prevent cheating? _Transparency_ or _security_?

In elaborating on these questions, the multi-disciplinary background of the author in data science, anthropology and law is very educational. From a qualitative point of view it is insightful to approach fairness from the following starting point:

> “Equity itself is not a simple one-size-fits-all solution. Equity involves discerning merit—who might deserve more or less depends on the features we think are relevant. [...] Our current definitions of virtue might ultimately prove outmoded, sociologically naive, or downright illogical when evaluated by other societies. For example, in history we see societies that valued quite different virtues for meritocracies, such as ability to memorize ancient texts, skill in warfare, religiosity, and ability to have children. So we should have some humility, recognizing that our current ideas of meritocracy [and equity] might not age well”

And regarding discrimination versus differentiation:

> “Note that discrimination—in the basic sense of sorting or segmenting people—is not necessarily wrong, as arguably all equity-oriented systems discriminate among individuals. The important consideration is the basis for discrimination—that is, the quality that is being used to sort and segment people. When the basis of discrimination is wrong, because it is immoral, prohibited by law, or unrelated to the ultimate goal of a system, such discrimination is improper.”

From a quantitative, technical point of view, the book relies heavily on open-source modules prepared by IBM, including the <a href="https://aif360.mybluemix.net/" target="_blank">AI Fairness 360</a>, <a href="https://aix360.mybluemix.net/" target="_blank">AI Explainability 360</a> and <a href="https://adversarial-robustness-toolbox.org/" target="_blank">Adversarial Robustness Toolbox (ART)</a>. Technical topics – like fair data, fairness interventions (pre-, in- and post-processing), interpretability and explainability algorithms – are all discussed at length in distinct chapters. Comprehensible code fragments are applied on widely cited data sets. In doing so, the book provides data and AI ethics practitioners with a broad overview of state-of-the-art academic research, mathematical notions of fairness and pressing moral concerns.

The book concludes with the claim that “Law is the ultimate arbiter of what matters for fairness in machine learning, and that’s a good thing”. As you might expect, at Algorithm Audit we agree with this standpoint. We support the idea that qualitative reasoning is always needed to define (algorithmic) fairness. But, at the same time we want to stress that legislation in itself is and will not suffice to realize ethical algorithms. Algorithm Audit advocates that organizations will always carry their own responsibility for ethical algorithms within and beyond the obligation of legal compliance. Why this is the case? Read the rationale for this viewpoint in the section _Why we exist_ on the home page of <a href="www.algorithmaudit.eu/" target="_blank">www.algorithmaudit.eu</a>. 

To conclude, Practical Fairness is a cutting edge guidebook for data and AI ethics practicioners to assess fairness both in qualitative and quantitative terms.


_Update 10-01-2022_

_We are happy to announce Aileen Nielsen is now part of Algorithm Audit’s Board of Advice._

