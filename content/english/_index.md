---
Banner:
  image: /images/svg-illustrations/main_illustration.svg
  tag: definition
  title: al-go-pru-dence
  phonetica: /æl.ɡə-ˈpruː.dəns/
  type: noun
  description1: Case-based normative advice for ethical algorithms
  description2: Guidance for decentralised self-assessment of fair AI
  description3: Jurisprudence for algorithms
  slogan:
    title: A European knowledge platform for
    labels:
      - text: AI bias testing
      - text: AI standards
Activity_Feed:
  enable: true
  button_text: View more...
  button_link: /events/activities/#events
  featured_activities:
    - title: Comparative review of 10 Fundamental Rights Impact Assessments (FRIAs)
      intro: >
        Comparative review of 10 existing FRIAs frameworks, evaluating them
        against 12 requirements across legal, organizational, technical and
        social dimensions. Our assessment shows a sharp divide regarding the
        length and completeness of FRIAs.
      link: /knowledge-platform/knowledge-base/comparative_review_10_frias/
      image: /images/knowledge_base/Comparative_review_10_FRIAs.png
      date: 21-09-2024
      type: white paper
  activities:
    - title: >-
        Guest speaker lunch seminar 'Risks of detection algorithms', Ministry of
        Justice en Security
      link: /events/activities/#events
      image: /images/events/MinJenV_logo.png
      date: 02-10-2024
      type: presentation
    - title: 'Masterclass ''Algorithm validation'', Association of Dutch Municipalities'
      link: /events/activities/#events
      image: /images/events/VNG_logo.png
      date: 19-09-2024
      type: presentation
    - title: >-
        Guest speaker in-depth session 'Bias, fairness and non-discrimination',
        Ministry of the Interior
      link: /events/activities/#events
      image: /images/supported_by/BZK.jpg
      date: 18-09-2024
      type: presentation
Supported_by:
  title: Collaborating with
  funders:
    - image: /images/supported_by/sidn.png
      link: 'https://www.sidnfonds.nl/projecten/open-source-ai-auditing'
      alt_text: Foundation for Internet and Democracy Netherlands
    - image: /images/supported_by/EUAISFund.png
      link: 'https://europeanaifund.org/announcing-our-2022-open-call-grantees/'
      alt_text: European AI & Society Fund
    - image: /images/supported_by/BZK.jpg
      link: >-
        https://www.rijksoverheid.nl/ministeries/ministerie-van-binnenlandse-zaken-en-koninkrijksrelaties
      alt_text: Dutch Ministry of the Interior
    - image: /images/supported_by/HAI.png
      link: 'https://hai.stanford.edu/ai-audit-challenge-2023-finalists'
      alt_text: Stanford University Human-Centered Artificial Intelligence Lab
    - image: /images/partners/DUO.png
      link: 'https://duo.nl'
      alt_text: Dutch Executive Agency for Education
    - image: /images/partners/NEN.svg
      link: 'https://www.nen.nl'
      alt_text: Dutch standardisation institute
    - image: /images/partners/CEN.jpg
      link: 'https://www.cencenelec.eu'
      alt_text: 'Europees standardisation committee '
    - image: /images/events/Amsterdam.png
      link: 'https://www.amsterdam.nl'
      alt_text: Municipality of Amsterdam
    - image: /images/supported_by/CoE.png
      link: 'https://www.coe.int/en/web/portal/home'
      alt_text: Council of Europe
Building_ai_audit_capacity:
  lines:
    - text_before: Building
      text_highlighted: AI auditing
      text_after: capacity
    - text_before: from a
      text_highlighted: not-for-profit
      text_after: perspective
Distinctive_in:
  enable: true
  title: Distinctive in
  width_m: 4
  width_s: 2
  feature_item:
    - name: Independence
      icon: fas fa-star-of-life
      content: >
        By working nonprofit and under explicit terms and conditions, we ensure
        the independence and quality of our audits and normative advice
    - name: Normative advice
      icon: fas fa-search
      content: >
        Mindful of societal impact our commissions provide normative advice on
        ethical issues that arise in algorithmic use cases
    - name: Public knowledge
      icon: fab fa-slideshare
      content: >
        Audits and corresponding advice (*algoprudence*) are made <a
        href="https://algorithmaudit.eu/algoprudence/"
        style="color:white;text-decoration: underline;">publicly available</a>,
        increasing collective knowledge how to deploy and use algorithms in an
        responsible way
Areas_of_AI_expertise:
  title: AI expertise
  enable: true
  width_m: 4
  width_s: 12
  button_text: Discuss collaboration
  button_link: /knowledge-platform/project-work/
  feature_item:
    - name: Algorithms for decision support
      icon: fas fa-divide
      content: >
        Auditing data-analysis methods and algorithms used for decision support.
        Among others by checking organizational checks and balances, and
        assessing the quantitative dimension
    - name: AI Act standards
      icon: fas fa-certificate
      content: >
        As Algorithm Audit is part of Dutch and Europen standardization
        organisations NEN and CEN-CENELEC, AI systems are audited according to
        the latest standards. See also our public <a
        href="https://algorithmaudit.eu/knowledge-platform/standards/"
        style="text-decoration: underline;">knowledge base</a> on
        standardization
    - name: Profiling
      icon: fas fa-chart-pie
      content: >
        Auditing rule-based and ML-driven profiling, e.g., differentiation
        policies, selection criteria, Z-testing, model validation and
        organizational aspects
    - name: FP-FN balancing
      icon: fa-solid fa-scale-balanced
      content: >
        Context-dependent review of ML and DL confusion matrix-based evaluation
        metrics, such as False Positives (FPs) and False Negatives (FNs)
    - name: Ranking
      icon: fas fa-ranking-star
      content: >
        Recommender systems are everywhere. With the new Digital Services Act
        (DSA) that came into force last summer, auditing ranking systems is
        highly relevant
    - name: Generative AI
      icon: fas fa-robot
      content: >
        Auditing training process of foundation models, among others selection
        of training data, human feedback for reinforcement learning and risk
        management, according to AI Act standards
Recent_audits:
  title: Recent audits
  feature_item:
    - name: 'Risk Profiling Social Welfare Re-examination '
      image: /images/reports/front_AA202302A.png
      link: >-
        /algoprudence/cases/aa202302_risk-profiling-for-social-welfare-reexamination/
      content: >
        Normative advice commission provides rationales why these variables are
        eligible or not as a profiling selection criterion for a xgboost
        algorithm
    - name: Technical audit indirect discrimination
      image: /images/algoprudence/AA202401/Cover.png
      link: /algoprudence/cases/aa202401_bias-prevented/
      content: >
        Assessment of risk distributions through Z-tests and bias test for
        various steps in algorithmic-driven decision-making process
Building_algoprudence:
  title: Building _algoprudence_
  button_text: Our working method
  button_link: /algoprudence/how-we-work/
  steps:
    - title: Identifying issue
      content: >
        Identifying a concrete ethical issue in a real algorithm or
        data-analysis tool
    - title: Problem statement
      content: >
        Describe ethical issue, legal aspects and hear stakeholders and affected
        groups
    - title: Advice commission
      content: >
        Deliberative conversation on ethical issue by diverse and inclusive
        advice commission
    - title: Public advice
      content: >
        Advice of commission is published together with problem statement on our
        website. Publicly sharing the problem statement and normative advice is
        called *algoprudence*
Advantages_of_algoprudence:
  title: Advantages of algoprudence
  image: /images/knowledge_base/White-paper_Algoprudence.png
  button_text: White paper on algoprudence
  button_link: /knowledge-platform/knowledge-base/white_paper_algoprudence/
  feature_item:
    - name: Learn & harmonize
      icon: fas fa-book-reader
      content: >
        [<span style="color:#005aa7">></span>](/algoprudence) Ignite collective
        learning process to deploy and audit responsible AI


        [<span style="color:#005aa7">></span> ](/algoprudence)Harmonizes the
        resolution of ethical questions and the interpretation of open legal
        norms
    - name: Question & criticize
      icon: fas fa-comment
      content: >
        [<span style="color:#005aa7">></span>](/algoprudence) Fostering
        criticism on normative decision-making through transparency


        [<span style="color:#005aa7">></span> ](/algoprudence)Informing public
        debate with important ethical issues to be discussed within  democratic
        sight
    - name: Inclusion & participation
      icon: fas fa-hands-helping
      content: >
        [<span style="color:#005aa7">></span> ](/algoprudence)Connecting various
        stakeholders to design ethical algorithms together with technical
        experts


        [<span style="color:#005aa7">></span> ](/algoprudence)European answer to
        deploy responsible AI systems
Title_gif:
  title: Jurisprudence for algorithms
Title_video:
  title: The Movie
  video_mp4: /videos/AA_video_(1080p).mp4
---

