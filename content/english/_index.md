---
Banner:
  title: Case-based knowledge for ethical algorithms
  image: images/main_illustration.svg
  content: Algorithm Audit is a nonprofit organization that builds and shares knowledge
    about ethical algorithms. Our independent audit commissions shed light on ethical
    issues that arise in concrete use cases of algorithmic tools and methods.
  button:
    enable: false
    label: Read our white paper
    link: knowledgebase
Features:
  enable: true
  title: What we do
  feature_item:
  - name: Auditing algorithms
    icon: fas fa-search
    content: Our audit commissions conduct case-based ethical reviews of algorithmic
      methods, in a holistic and context-sensitive way that is mindful of societal
      impact.
  - name: Independent
    icon: fas fa-star-of-life
    content: By working nonprofit and under explicit terms and conditions, we ensure
      the independence, academic quality and diversity of our audit commissions and
      of our ethical advice.
  - name: Ethics beyond compliance
    icon: fas fa-leaf
    content: We help organizations committed to ethical algorithms to make judgments
      about fairness and ethics beyond the requirements of legal compliance.
  - name: Public knowledge
    icon: fab fa-slideshare
    content: All our cases and corresponding advice are made publicly available, increasing
      collective knowledge how to devise and use algorithms in an ethical way.
  - name: Techno-ethical jurisprudence
    icon: fas fa-book-reader
    content: From our case-based knowledge, data scientists can distill best practices
      for ethical algorithms. Over time a helpful resource for techno-ethical issues
      will emerge.
  - name: Joint effort
    icon: fas fa-hands-helping
    content: Let's remove boundaries between public and private organizations that
      face similar ethical concerns. We believe in a collective approach to realise
      ethical algorithms. We offer a platform of collaboration for academics, developers
      and policy makers.
How_we_work:
  enable: true
  service_item:
  - title: How we work
    images:
    - images/howwework.svg
    content: ''
    button:
      enable: true
      label: Cases we work on
      link: cases
With_whom_we_work:
  enable: true
  service_item:
  - title: Who we work with
    images:
    - images/howwework.svg
    content: We work together with international experts from various backgrounds,
      e.g. ethicists, legal professionals, data scientists. The composition of audit
      commissions varies per case. Most of the experts are affiliated with academic
      institutions. The Algorithm Audit team facilitates the procurement of sufficient
      background information about the case, after which the experts conduct an in-depth
      study, first individually and then collectively. Our team drafts a report that
      condenses the varied views of the commission.The report published by Algorithm
      Audit has been agreed upon by the commission members.
    button:
      enable: false
      label: Cases we work on
      link: "#/cases"
Why_we_exist:
  enable: true
  content: Current legislation falls short to
  service_item:
  - title: Why we exist
    images:
    - images/societal_impact.svg
    content: "Algorithm Audit was founded on the idea that ethics in algorithmic methods
      urgently needs case-based experience and a bottom-up approach. We believe existing
      and proposed legislation is and will not suffice to realize ethical algorithms.
      Why not?\n- The conditions given in [GDPR Article 22 (2)](https://gdpr-info.eu/art-22-gdpr/)
      under which automated decision-making (ADM) and profiling is allowed are open
      for broad interpretation. Allowing wide-ranging ADM under the sole condition
      of contract agreement opens the door for large scale unethical algorithmic practices
      without accountability and public awareness.\n- The newly proposed [AI Act of
      the European Commission](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206)
      aims to regulate the use of high-risk algorithms, but remains too generic. For
      example, it does not provide precise guidelines how to identify and mitigate
      ethical issues such as algorithmic discrimination. In addition, machine learning
      practice that falls outside the high-risk category is not exempt from major
      ethical concerns. The legal measures, which only become effective in several
      years, will become a playground for legal experts and lawyers and will not directly
      offer concrete and extensive guidelines on ethical algorithms for organizations
      in industry and government. Hence, organizations will still need to make up
      their own mind about context-specific ethical guidelines and procedures in their
      use of machine learning.\n\n- [Perspective 3.1.1](https://www.rekenkamer.nl/onderwerpen/algoritmes-digitaal-toetsingskader/ethiek)
      in the Guidelines for Algorithms of the Dutch Court of Auditors argues that
      ethical algorithms are not allowed to “discriminate and that bias should be
      minimised”. Missing from this judgment is a discussion of what precisely constitutes
      bias in the context of machine learning and what would be good methods to ascertain
      and mitigate algorithmic discrimination. Absent a clear legal framework, it
      is up to organizations to formulate context-sensitive approaches to combat discrimination.\n\n-
      The Impact Assessment Human Rights and Algorithms (IAMA) and the Handbook for
      Non-Discrimination, both developed by the Dutch government, assess discriminatory
      practice mainly by asking questions that are meant to stimulate self-reflection.
      It does not provide answers or concrete guidelines how to realise ethical algorithms.\n\nWe
      believe a case-based and context sensitive approach is indispensible to a practical
      approach to ethical algorithms. We should not expect top-down regulation and
      legislation to solve all ethical problems in AI and machine learning. Taking
      all contested algorithmic cases to court is practically infeasible. More importantly,
      organizations will always carry their own responsibility for ethical algorithms
      within and beyond the obligation of legal compliance. Hence, new bottom-up initiatives
      like Algorithm Audit are necessary to support these organizations and to strengthen
      ethical practice in ADM and machine learning. We provide a platform where experts
      in AI ethics can interact with, learn from and steer actual algorithmic practice
      and surrounding ethical concerns. We increase public knowledge and stimulate
      an informed debate about what ethical algorithms we desire as a society in various
      contexts. As such, Algorithm Audit contributes to SDG16 – Peace, Justice and
      Strong Institutions in the digital domain. "
Get_in_touch:
  enable: true
  title: Get in touch
  content: Do you have an ethical issue for review? Or want to share ideas? Let us
    know!
Supported_by:
  enable: true
  Suported_by:
  - title: Our initiative is supported by
    img1:
    - images/sidn.png
    img2:
    - 

---
