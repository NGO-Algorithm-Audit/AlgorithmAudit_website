---
Banner:
  title_line1: Building public knowledge
  title_line2_before: for
  title_line2_underline: responsible
  title_line2_after: algorithms
  title_mobile_line1: Building public
  title_mobile_line2: knowledge for
  title_mobile_line3_underline: responsible
  title_mobile_line3_after: algorithms
  phonetica: /æl.ɡə-ˈpruː.dəns/
  type: noun
  description1: Case-based normative advice for ethical algorithms
  description2: Guidance for decentralised self-assessment of fair AI
  description3: Jurisprudence for algorithms
  slogan:
    title: A European knowledge platform for
    labels:
      - text: AI bias testing
      - text: AI standards
About:
  content: >
    Who decides on the algorithms that shape our daily lives? We believe this
    belongs to all of us. Our team of data scientists, lawyers, and ethicists
    tackles value-based questions at the heart of AI. As a knowledge platform,
    we bridge the gap between policy initiatives, academic insights and
    case-based experience. Through open-source tools, independent validation and
    advice, we translate knowledge into action. Connect with us to make
    responsible AI a shared effort.
overview_block:
  activities:
    - title: Knowledge platform
      subtitle: Statistical and legal expertise
      url: /knowledge-platform/
      icon: fa-light fa-layer-group
      color: '#E3F0FE'
    - title: Algoprudence
      subtitle: Case-based normative advice
      url: /algoprudence/
      icon: fa-light fa-scale-balanced
      color: '#F7CDBF'
    - title: Technical tools
      subtitle: Open source AI auditing tools
      url: /technical-tools/
      icon: fa-light fa-toolbox
      color: '#FFFDE4'
    - title: Project work
      subtitle: 'Validation, AI Act etc.'
      url: /knowledge-platform/project-work/
      icon: fa-light fa-magnifying-glass-plus
      color: '#E3F0FE'
Activity_Feed:
  featured_title: Featured
  featured_activities:
    - title: >-
        Public standard 'Meaningful human intervention for risk profiling
        algorithms'
      intro: >
        Step-by-step guide to prevent prohibited automated decision-making
        solely based on profilings, as stated in Article 22 GDPR. Based on
        case-based experiences with risk profiling algorithms and aligned with
        recent literature.
      link: >-
        /knowledge-platform/knowledge-base/public_standard_meaningful_human_intervention/
      image: /images/knowledge_base/Public_standard_meaningful_human_intervention.png
      date: 15-05-2025
      type: public standard
  featured_button_text: More items
  featured_button_link: /knowledge-platform/knowledge-base/
  items_title: Upcoming events
  activities:
    - title: Guest lecture 'Fairness and Algorithms' ETH Zürich
      link: /events/activities/#events
      image: /images/events/eth-zurich.jpg
      date: 23-05-2025
      type: event
    - title: Panel discussion CPDP'25
      link: /events/activities/#events
      image: /images/events/cpdp-logo-2025.svg
      date: 21-05-2025
      type: panel discussion
    - title: >-
        Masterclass 'From data to decision', Jantina Tammes School of Digital
        Society, Technology and AI University of Groningen
      link: /events/activities/#events
      image: /images/events/RUG.png
      date: 06-05-2025
      type: event
  items_button_text: More events
  items_button_link: /events/activities/
Areas_of_AI_expertise:
  title: AI expertise
  enable: true
  width_m: 4
  width_s: 12
  feature_item:
    - name: Algorithms for decision support
      icon: fas fa-divide
      content: >
        Auditing data-analysis methods and algorithms used for decision support.
        Among others by checking organizational checks and balances, and
        assessing the quantitative dimension
    - name: AI Act standards
      icon: fas fa-certificate
      content: >
        As Algorithm Audit is part of Dutch and Europen standardization
        organisations NEN and CEN-CENELEC, AI systems are audited according to
        the latest standards. See also our public <a
        href="https://algorithmaudit.eu/knowledge-platform/standards/"
        style="text-decoration: underline;">knowledge base</a> on
        standardization
    - name: Profiling
      icon: fas fa-chart-pie
      content: >
        Auditing rule-based and ML-driven profiling, e.g., differentiation
        policies, selection criteria, Z-testing, model validation and
        organizational aspects
    - name: FP-FN balancing
      icon: fa-solid fa-scale-balanced
      content: >
        Context-dependent review of ML and DL confusion matrix-based evaluation
        metrics, such as False Positives (FPs) and False Negatives (FNs)
    - name: Ranking
      icon: fas fa-ranking-star
      content: >
        Recommender systems are everywhere. With the new Digital Services Act
        (DSA) that came into force last summer, auditing ranking systems is
        highly relevant
    - name: Generative AI
      icon: fas fa-robot
      content: >
        Auditing training process of foundation models, among others selection
        of training data, human feedback for reinforcement learning and risk
        management, according to AI Act standards
  button_text: Discuss collaboration
  button_link: /knowledge-platform/project-work/
Distinctive_in:
  title: Distinctive in
  enable: true
  width_m: 4
  width_s: 2
  feature_item:
    - name: Independence
      icon: fas fa-star-of-life
      content: >
        By working nonprofit and under explicit terms and conditions, we ensure
        the independence and quality of our audits and normative advice
    - name: Normative advice
      icon: fas fa-search
      content: >
        Mindful of societal impact our commissions provide normative advice on
        ethical issues that arise in algorithmic use cases
    - name: Public knowledge
      icon: fab fa-slideshare
      content: >
        Audits and corresponding advice (*algoprudence*) are made <a
        href="https://algorithmaudit.eu/algoprudence/" style="text-decoration:
        underline;">publicly available</a>, increasing collective knowledge how
        to deploy and use algorithms in an responsible way
  button_text: Project work
  button_link: /knowledge-platform/project-work/
Supported_by:
  title: Collaborating with
  funders:
    - image: /images/supported_by/sidn.png
      link: 'https://www.sidnfonds.nl/projecten/open-source-ai-auditing'
      alt_text: Foundation for Internet and Democracy Netherlands
    - image: /images/supported_by/EUAISFund.png
      link: 'https://europeanaifund.org/announcing-our-2022-open-call-grantees/'
      alt_text: European AI & Society Fund
    - image: /images/supported_by/BZK.jpg
      link: >-
        https://www.rijksoverheid.nl/ministeries/ministerie-van-binnenlandse-zaken-en-koninkrijksrelaties
      alt_text: Dutch Ministry of the Interior
    - image: /images/supported_by/HAI.png
      link: 'https://hai.stanford.edu/ai-audit-challenge-2023-finalists'
      alt_text: Stanford University Human-Centered Artificial Intelligence Lab
    - image: /images/supported_by/DUO.png
      link: 'https://duo.nl'
      alt_text: Dutch Executive Agency for Education
    - image: /images/partners/NEN.svg
      link: 'https://www.nen.nl'
      alt_text: Dutch standardisation institute
    - image: /images/partners/CEN.jpg
      link: 'https://www.cencenelec.eu'
      alt_text: 'Europees standardisation committee '
    - image: /images/events/Amsterdam.png
      link: 'https://www.amsterdam.nl'
      alt_text: Municipality of Amsterdam
    - image: /images/supported_by/CoE.png
      link: 'https://www.coe.int/en/web/portal/home'
      alt_text: Council of Europe
  button_text: And more
  button_link: /funded-by
Title_video:
  title: The Movie
  video_mp4: /videos/AA_video_(1080p).mp4
---

