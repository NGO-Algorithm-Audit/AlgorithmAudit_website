---
Banner:
  image: /images/svg-illustrations/main_illustration.svg
  tag: definition
  title_line1: Building public knowledge
  title_line2_before: for
  title_line2_underline: responsible
  title_line2_after: algorithms
  title_mobile_line1: Building public
  title_mobile_line2: knowledge for
  title_mobile_line3_underline: responsible
  title_mobile_line3_after: algorithms
  phonetica: /æl.ɡə-ˈpruː.dəns/
  type: noun
  description1: Case-based normative advice for ethical algorithms
  description2: Guidance for decentralised self-assessment of fair AI
  description3: Jurisprudence for algorithms
  slogan:
    title: A European knowledge platform for
    labels:
      - text: AI bias testing
      - text: AI standards
Core_Activities:
  activities:
    - title: Knowledge platform
      subtitle: Statistical and legal expertise
      url: /knowledge-platform/
      icon: fa-light fa-layer-group
      color: '#E3F0FE'
    - title: Algoprudence
      subtitle: Case-based normative advise
      url: /algoprudence/
      icon: fa-light fa-scale-balanced
      color: '#F7CDBF'
    - title: Technical tools
      subtitle: Open source AI auditing tools
      url: /technical-tools/
      icon: fa-light fa-toolbox
      color: '#D5EBDB'
    - title: Project work
      subtitle: Validation, AI Act etc.
      url: /knowledge-platform/project-work/
      icon: fa-light fa-magnifying-glass-plus
      color: '#E3F0FE'
About:
  content: >
    Who decides on the algorithms that shape our society? We believe this belongs to all of us. At Algorithm Audit, we tackle the value-based questions at the heart of AI and data modelling. We specialise in transparent deliberation over technical choices with regard to their real-world consequences. As a nonprofit knowledge platform, our team of data scientists, lawyers, and ethicists bridge the gap between industry, academia and public policy, connecting bottom-up experience with state-of-the-art insights. Through open-source tools, independent validation, and public sector guidance, we translate knowledge into action. Connect with us to make responsible AI a shared effort.
Activity_Feed:
  enable: true
  button_text: View more...
  button_link: /events/activities/#events
  featured_activities:
    - title: Public standard profiling algorithms
      intro: >
        Based on our case-based experience with auditing risk profiling systems,
        Algorithm Audit publishes a public standard providing qualitative and
        qualitative safeguards for responsible use of these type of algorithms.
      link: /knowledge-platform/knowledge-base/public_standard_profiling/
      image: /images/knowledge_base/Public_standard_profiling.png
      date: 22-10-2024
      type: white paper
  activities:
    - title: Guest lecture ethical AI Utrecht University
      link: /events/activities/#events
      image: /images/events/uu-logo.png
      date: 10-03-2025
      type: event
    - title: >-
        Demo open-source AI auditing tools during innovation day Dutch Ministry
        of the Interior
      link: /events/activities/#events
      image: /images/events/MinBZK_logo.jpg
      date: 13-02-2025
      type: presentatie
    - title: >-
        Presentation Responsible AI - Innovation Festival Dutch Ministry of
        Infrastructure and Water
      link: /events/activities/#events
      image: /images/events/MinIenW_logo.png
      date: 13-02-2025
      type: presentatie
Supported_by:
  title: Collaborating with
  funders:
    - image: /images/supported_by/sidn.png
      link: 'https://www.sidnfonds.nl/projecten/open-source-ai-auditing'
      alt_text: Foundation for Internet and Democracy Netherlands
    - image: /images/supported_by/EUAISFund.png
      link: 'https://europeanaifund.org/announcing-our-2022-open-call-grantees/'
      alt_text: European AI & Society Fund
    - image: /images/supported_by/BZK.jpg
      link: >-
        https://www.rijksoverheid.nl/ministeries/ministerie-van-binnenlandse-zaken-en-koninkrijksrelaties
      alt_text: Dutch Ministry of the Interior
    - image: /images/supported_by/HAI.png
      link: 'https://hai.stanford.edu/ai-audit-challenge-2023-finalists'
      alt_text: Stanford University Human-Centered Artificial Intelligence Lab
    - image: /images/partners/DUO.png
      link: 'https://duo.nl'
      alt_text: Dutch Executive Agency for Education
    - image: /images/partners/NEN.svg
      link: 'https://www.nen.nl'
      alt_text: Dutch standardisation institute
    - image: /images/partners/CEN.jpg
      link: 'https://www.cencenelec.eu'
      alt_text: 'Europees standardisation committee '
    - image: /images/events/Amsterdam.png
      link: 'https://www.amsterdam.nl'
      alt_text: Municipality of Amsterdam
    - image: /images/supported_by/CoE.png
      link: 'https://www.coe.int/en/web/portal/home'
      alt_text: Council of Europe
Building_ai_audit_capacity:
  lines:
    - text_before: Building
      text_highlighted: AI auditing
      text_after: capacity
    - text_before: from a
      text_highlighted: not-for-profit
      text_after: perspective
Distinctive_in:
  enable: true
  title: Distinctive in
  width_m: 4
  width_s: 2
  feature_item:
    - name: Independence
      icon: fas fa-star-of-life
      content: >
        By working nonprofit and under explicit terms and conditions, we ensure
        the independence and quality of our audits and normative advice
    - name: Normative advice
      icon: fas fa-search
      content: >
        Mindful of societal impact our commissions provide normative advice on
        ethical issues that arise in algorithmic use cases
    - name: Public knowledge
      icon: fab fa-slideshare
      content: >
        Audits and corresponding advice (*algoprudence*) are made <a
        href="https://algorithmaudit.eu/algoprudence/"
        style="color:white;text-decoration: underline;">publicly available</a>,
        increasing collective knowledge how to deploy and use algorithms in an
        responsible way
Areas_of_AI_expertise:
  title: AI expertise
  enable: true
  width_m: 4
  width_s: 12
  button_text: Discuss collaboration
  button_link: /knowledge-platform/project-work/
  feature_item:
    - name: Algorithms for decision support
      icon: fas fa-divide
      content: >
        Auditing data-analysis methods and algorithms used for decision support.
        Among others by checking organizational checks and balances, and
        assessing the quantitative dimension
    - name: AI Act standards
      icon: fas fa-certificate
      content: >
        As Algorithm Audit is part of Dutch and Europen standardization
        organisations NEN and CEN-CENELEC, AI systems are audited according to
        the latest standards. See also our public <a
        href="https://algorithmaudit.eu/knowledge-platform/standards/"
        style="text-decoration: underline;">knowledge base</a> on
        standardization
    - name: Profiling
      icon: fas fa-chart-pie
      content: >
        Auditing rule-based and ML-driven profiling, e.g., differentiation
        policies, selection criteria, Z-testing, model validation and
        organizational aspects
    - name: FP-FN balancing
      icon: fa-solid fa-scale-balanced
      content: >
        Context-dependent review of ML and DL confusion matrix-based evaluation
        metrics, such as False Positives (FPs) and False Negatives (FNs)
    - name: Ranking
      icon: fas fa-ranking-star
      content: >
        Recommender systems are everywhere. With the new Digital Services Act
        (DSA) that came into force last summer, auditing ranking systems is
        highly relevant
    - name: Generative AI
      icon: fas fa-robot
      content: >
        Auditing training process of foundation models, among others selection
        of training data, human feedback for reinforcement learning and risk
        management, according to AI Act standards
Recent_audits:
  title: Recent audits
  feature_item:
    - name: 'Risk Profiling Social Welfare Re-examination '
      image: /images/reports/front_AA202302A.png
      link: >-
        /algoprudence/cases/aa202302_risk-profiling-for-social-welfare-reexamination/
      content: >
        Normative advice commission provides rationales why these variables are
        eligible or not as a profiling selection criterion for a xgboost
        algorithm
    - name: Technical audit indirect discrimination
      image: /images/algoprudence/AA202401/Cover.png
      link: /algoprudence/cases/aa202401_bias-prevented/
      content: >
        Assessment of risk distributions through Z-tests and bias test for
        various steps in algorithmic-driven decision-making process
Building_algoprudence:
  title: Building _algoprudence_
  button_text: Our working method
  button_link: /algoprudence/how-we-work/
  steps:
    - title: Identifying issue
      content: >
        Identifying a concrete ethical issue in a real algorithm or
        data-analysis tool
    - title: Problem statement
      content: >
        Describe ethical issue, legal aspects and hear stakeholders and affected
        groups
    - title: Advice commission
      content: >
        Deliberative conversation on ethical issue by diverse and inclusive
        advice commission
    - title: Public advice
      content: >
        Advice of commission is published together with problem statement on our
        website. Publicly sharing the problem statement and normative advice is
        called *algoprudence*
Advantages_of_algoprudence:
  title: Advantages of algoprudence
  image: /images/knowledge_base/White-paper_Algoprudence.png
  button_text: White paper on algoprudence
  button_link: /knowledge-platform/knowledge-base/white_paper_algoprudence/
  feature_item:
    - name: Learn & harmonize
      icon: fas fa-book-reader
      content: >
        [<span style="color:#005aa7">></span>](/algoprudence) Ignite collective
        learning process to deploy and audit responsible AI


        [<span style="color:#005aa7">></span> ](/algoprudence)Harmonizes the
        resolution of ethical questions and the interpretation of open legal
        norms
    - name: Question & criticize
      icon: fas fa-comment
      content: >
        [<span style="color:#005aa7">></span>](/algoprudence) Fostering
        criticism on normative decision-making through transparency


        [<span style="color:#005aa7">></span> ](/algoprudence)Informing public
        debate with important ethical issues to be discussed within  democratic
        sight
    - name: Inclusion & participation
      icon: fas fa-hands-helping
      content: >
        [<span style="color:#005aa7">></span> ](/algoprudence)Connecting various
        stakeholders to design ethical algorithms together with technical
        experts


        [<span style="color:#005aa7">></span> ](/algoprudence)European answer to
        deploy responsible AI systems
Title_gif:
  title: Jurisprudence for algorithms
Title_video:
  title: The Movie
  video_mp4: /videos/AA_video_(1080p).mp4
---

