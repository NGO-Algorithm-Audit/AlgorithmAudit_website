---
icon: fas fa-greater-than-equal
layout: case
title: Preventing prejudice
subtitle: >
  Technical audit (TA:AA:2024:01) – Findings and recommendations regarding
  rule-based risk profiling as used in a Dutch public sector organisation
  control process
image: /images/algoprudence/AA202401/Cover_EN.png
form1:
  title: React to this technical audit
  content: >-
    Your reaction will be sent to the auditing team. The team will review your
    response and, if it complies with Algorithm Audit's guidelines, the reaction
    will be placed in the Discussion & debate section above.
  button_text: Submit
  backend_link: 'https://formspree.io/f/xyyrjyzr'
  id: case-reaction
  questions:
    - label: |
        Name
      id: name
      required: true
      type: text
    - label: |
        Affiliated organization
      id: affiliated-organization
      type: text
    - label: |
        Reaction
      id: reaction
      required: true
      type: textarea
    - label: |
        Contact details
      id: contact-details
      required: true
      type: email
      placeholder: Mail address
---

{{< tab_header width="4" tab1_id="description" tab1_title="Description of technical audit" tab2_id="actions" tab2_title="Actions following technical audit" tab3_id="discussion" tab3_title="Discussion & debate" default_tab="description" >}}

{{< tab_content_open icon="fa-greater-than-equal" title="Preventing prejudice" id="description" >}}

#### Algoprudence idetification code

TA:AA:2024:01

#### Summary

In the period 2012-2022,  students who lived close to their parent(s) have been selected significantly more often by Dutch public sector organisation DUO than other students. The algorithm used to support the selection procedure performed as expected. The combination of the algorithm-driven risk scoring and manual selection for the contorl process resulted in a significant overrepresentation of certain groups. Selected students were visited at home to verify whether they were not misusing college allowances. This is the main conclusion of the audit conducted by the Algorithm Audit Foundation on behalf of DUO. DUO's control process came under scrutiny in 2023 following <a href="https://nos.nl/op3/video/2479701-zo-checkt-duo-of-jij-fraudeert-en-dat-systeem-rammelt" target="_blank">news items</a> from Investico and NOS, which stated that students with a migration background were more often accused of abuse than other students.
berichtgeving

A press release can be found [here](/events/press_room/#DUO).

#### Source of the case

Education Executive Agency of The Netherlands (DUO)

#### Algoprudence

The technical audit report (TA:AA:2024:01) can be downloaded [here](https://drive.google.com/file/d/17dwU4zAqpyixwVTKCYM7Ezq1VM5_kcDa/preview).

{{< embed_pdf url="/pdf-files/algoprudence/TA_AA202401/TA_AA202401_Preventing_prejudice.pdf" >}}

<!-- #### AI Act standards

* **Risk management:** aa
* **Governance & data quality:** aa
  * **420001: 
* **Record keeping:** aa
* **Transparency provisions:** aa
* **Human oversight:** aa
* **Accuracy specifications:** aa
* **Robustness specifications:** aa
* **Quality management system:** aa -->

#### Funded by

<br>

{{< image image1="/images/partners/DUO.png" alt1="Dutch public sector organisation DUO" caption1="Dutch public sector organisation DUO" image2="" alt2="" caption2="" id="funded-by" image3="" alt3="" caption3="" link1="https://duo.nl/particulier/" width_desktop="4" width_mobile="6" link2="" link3="" >}}

{{< tab_content_close >}}

{{< tab_content_open icon="" title="" id="actions" >}}

{{< accordions_area_open id="actions" >}}

{{< accordion_item_open title="Dutch cabinet's response to investigations DUO's control process" image="/images/algoprudence/AA202401/Actions/TK.svg" id="cabinet-reaction" date="01-03-2024" tag1="political action" >}}

##### Description

Report *Preventing prejudice* has been <a href="https://www.rijksoverheid.nl/documenten/kamerstukken/2024/03/01/kabinetsreactie-onderzoek-naar-controleproces-uitwonendenbeurs" target="_blank">sent</a> as part of the Internal research documents to  Dutch Parliament

{{< accordion_item_close >}}

{{< accordion_item_open title="DUO apologizes for indirect discrimination in college allowances control process" image="/images/partners/DUO.png" id="DUO-apologies" date="01-03-2024" tag1="press release" >}}

##### Description

<a href="https://duo.nl/organisatie/pers/excuses-voor-indirecte-discriminatie-bij-controles-op-de-uitwonendenbeurs.jsp" target="_blank">Press release</a> DUO

{{< accordion_item_close >}}

{{< accordions_area_close >}}

{{< tab_content_close >}}

{{< tab_content_open id="discussion" >}}

{{< accordions_area_open id="discussion" >}}

{{< accordion_item_open title="Reaction Netherlands Human Rights Institute on age discrimination" id="cvrm" background_color="#eef2f6" date="12-04-2024" tag1="reaction" image="/images/algoprudence/AA202302/Discussion&debate/CvRM.svg" >}}

#### Age Discrimination

Policies, such as those implemented by public sector agencies investigating (un)duly granted social welfare or employers seeking new employees, can intentionally or unintentionally lead to differentiation between certain groups of people. If an organization makes this distinction based on grounds that are legally protected, such as gender, origin, sexual orientation, or a disability or chronic illness, and there is no valid justifying reason for doing so, then the organization is engaging in prohibited discrimination. We refer to this as discrimination.

But what about age? Both the Rotterdam-algorithm and DUO-algorithm, as studied by Algorithm Audit, differentiated based on age. However, in these cases, age discrimination does not occur.

EU non-discrimination law also prohibits discrimination on the basis of age. For instance, arbitrarily rejecting a job applicant because someone is too old is not unlawful. However, legislation regarding age differentiation allows more room for a justifying argument than for the aforementioned personal characteristics. This is especially true when the algorithm is not applied in the context of labor.

Therefore, in the case of detecting unduly granted social welfare or misuse of college loan, it is not necessarily prohibited for an algorithm to consider someone's age. However, there must be a clear connection between age and the aim pursued. Until it is shown that someone's age increases the likelihood of misuse or fraud, age is ineligible as a selection criteria in algorithmic-driven selection procedures. For example, pertaining to disability allowances for youngsters (Wajong) a clear connection exists and an algorithm can lawfully differentiate upon age.

{{< accordion_item_close >}}

{{< accordions_area_close >}}

{{< tab_content_close >}}

{{< form1 >}}
