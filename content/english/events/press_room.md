---
title: Press releases
subtitle: >
  Press releases of Algorithm Audit. Get in touch with the organisation by
  submitting [this](/about/contact/) contact form.
image: /images/svg-illustrations/about.svg
---

{{< accordions_area_open id="DUO" >}}

{{< accordion_item_open title="Irregularities identified in college allowances control process by Dutch public sector organization DUO" id="DUO_CBS" background_color="#ffffff" date="22-05-2024" tag1="DUO" tag2="CBS" tag3="bias analysis" image="/images/partners/DUO.png" >}}

 Irregularities identified in college allowances control process by Dutch public sector organization DUO

THE HAGUE – In its control process into misuse of the allowances for students living away from home, Dutch public sector organization DUO selected individuals who lived close to their parent(s) significantly more often. The risk-taxation algorithm, that was used as an assisting tool for selecting students, worked as expected. However, the combination of the algorithm and manual selection resulted in a large overrepresentation of certain groups. Selected students were visited at home to inspect whether allowances were unduly granted. This is the main conclusion of research carried out by NGO Algorithm Audit on behalf of DUO. DUO’s control process was discredited in 2023 after media attention, in which was mentioned that students with a migration background were accused of misuse more often than other students.

Students who were registered living close to their parent(s) were significantly more likely to be selected for a home visit. As a result of such investigations, DUO decides whether the allowances for people living away from home has been frauded with. Such a deviation would not have occurred if the output of a rule-based algorithm had been followed. This algorithm was used by the Dutch Education Executive Agency (‘DUO’) to assign a risk score to all students (more than 500,000) living away from their parent(s) in the period 2012-2022. It is obvious that specific work instructions – which encourage the manual selection of students who are registered near the parental address – have resulted in this disparity. That is the main conclusion of the study Bias prevented of NGO Algorithm Audit, which was sent to the Dutch Parliament on March 1, 2024.

Furthermore, the study does not prove statistical evidence between multiple selection criteria as used in the risk assessment algorithm (i.e., type of education and age) and unduly granted allowances. For the selection criterion distance to parent(s), statistical evidence for such a link with has been found. These results are based on a statistical analysis of risk distributions in random samples drawn from the student population in 2014 and 2017. NGO Algorithm Audit also found that the algorithm does adhere to current standards set for usage of algorithms used in decision-making processes by the Dutch government. At the request of DUO, standards from 2023 were used to assess its decision-making process which has been deployed in the period 2012-2014. For instance, no rationale has been documented why important choices were made during the design phase of the algorithm. Furthermore, the control process has not undergone scrutiny for indirect bias, neither during the design phase nor during the deployment phase.

Commissioned by DUO, NGO Algorithm Audit is auditing the control process of college allowances. The reason for this is that students with a migration background are more often accused of misusage of allowances. Whether a relationship exists between the deviating group, that has been selected significantly more often for a home visit, and students with a migration background will become clear from further research that is currently being undertaken. Data requested from Statistics Netherlands (CBS) will be analyzed to measure the percentage of students per country of origin for each step of the allowances control process. According to NGO Algorithm Audit, publicly accessible data – such as aggregated migration statistics per ZIP code area or the average distance that certain demographic groups live from their parent(s) – is too inaccurate to be used for this delicate research. According to NGO Algorithm Audit, it is too early to conclude whether students with a migration background are actually being disadvantaged, although the study has not demonstrated the opposite. NGO Algorithm Audit does note that there is no evidence of direct discrimination on the basis of migration background in the algorithm.

The results of the studies will be used to determine whether risk profiling can be used responsibly in the future to detect misuse of college allowances. This is relevant as these allowances have been reintroduced since this academic year for students following a higher vocational study (hbo) or a scientific/academic study (wo). DUO and NGO Algorithm Audit will continue to work together in 2024 to interpret the results of the studies together with various societal stakeholders. Currently, DUO solely randomly selects students for checking cases of fraud.

The full report Bias prevented can be found here.

01-03-2024

{{< accordion_item_close >}}

{{< accordion_item_open title="Afwijkingen geconstateerd in controleproces DUO naar misbruik met uitwonendenbeurs" id="DUO" background_color="#ffffff" date="01-03-2024" tag1="DUO" image="/images/partners/DUO.png" tag2="audit rapport" >}}

<b>DEN HAAG – DUO selecteerde in onderzoek naar misbruik met de uitwonendenbeurs aanzienlijk
vaker studenten die dicht bij hun ouder(s) woonden. Het algoritme dat ter ondersteuning van
de selectie werd gebruikt functioneerde naar verwachting. De combinatie van het
algoritme en handmatige selectie zorgde echter voor een grote oververtegenwoordiging
van bepaalde groepen. Geselecteerde studenten werden thuis
bezocht om te controleren of zij geen misbruik maakten. Dit is de belangrijkste conclusie van het
onderzoek dat Stichting Algorithm Audit uitvoert in opdracht van DUO. Het controleproces van DUO kwam in 2023 in opspraak na <a href="https://nos.nl/op3/video/2479701-zo-checkt-duo-of-jij-fraudeert-en-dat-systeem-rammelt" target="_blank">berichtgeving</a> van Investico en NOS, waarin werd vermeld dat studenten met een migratieachtergrond vaker dan andere studenten werden beschuldigd van misbruik.</b>

Studenten die dicht bij hun ouder(s) stonden ingeschreven zijn aanzienlijk
vaker geselecteerd voor een huisbezoek. DUO beslist naar aanleiding van dergelijke
controles of er misbruik is gemaakt van de uitwonendenbeurs. Deze afwijkijking is
veel groter dan wanneer uitsluitend het regel-gebaseerde algoritme zou zijn gevolgd
dat de Dienst Uitvoering Onderwijs (‘DUO’) gebruikte om in de periode 2012-2022
aan alle uitwonende studenten (ruim 500.000) een risicoscore toe te kennen. Voor
de hand ligt dat specifieke werkinstructies – die aansporen tot het handmatig
selecteren van studenten die nabij het ouderlijk adres staan ingeschreven –
hier de oorzaak van zijn. Dat is de belangrijkste conclusie van het rapport Vooringenomenheid
voorkomen van Stichting Algorithm Audit dat op 1 maart 2024 naar de Tweede
Kamer is gestuurd. 

Uit het onderzoek volgt verder onvoldoende
statistisch verband tussen een aantal selectiecriteria die in het door DUO
gehanteerde risicotaxatie-algoritme zijn gebruikt (te weten onderwijsvorm en
leeftijd). Voor het selectiecriterium afstand tot ouder(s) is wel statistisch
bewijs voor een verband met onrechtmatigheid gevonden. Deze resultaten zijn
gebaseerd op een statistische analyse van misbruikcontrole op basis van aselecte
steekproeven uit 2014 en 2017. Ook stelt Stichting Algorithm Audit vast dat het
gebruikte algoritme niet voldoet aan de eisen die op dit moment worden gesteld
aan door de Nederlandse overheid gebruikte algoritmes. Op verzoek van DUO is
aan deze nieuwste normen voor het gebruik van algoritmes door de overheid
getoetst. Zo ontbreekt er een gedegen onderbouwing van keuzes die tijdens het ontwerp
van het algoritme zijn gemaakt. Daarnaast is niet gebleken van onderzoek naar
mogelijke indirecte vooringenomenheid van het gebruikte algoritme, noch bij het
opstellen, noch bij het gebruik ervan.

In opdracht van DUO doet de Stichting
Algorithm Audit onafhankelijk onderzoek naar het controleproces
uitwonendenbeurs. Aanleiding is dat studenten met een migratieachtergrond vaker
worden <a href="https://nos.nl/op3/video/2479701-zo-checkt-duo-of-jij-fraudeert-en-dat-systeem-rammelt" target="_blank">beschuldigd</a>
van misbruik met studiefinanciering. Of de groep die bovenmatig vaak is
geselecteerd voor een huisbezoek inderdaad ook bovenmatig vaak een
migratieachtergrond heeft zal blijken uit vervolgonderzoek dat op dit moment
wordt uitgevoerd. Hierbij gebruikt Stichting Algorithm Audit data die zijn
opgevraagd bij het Centraal Bureau voor de Statistiek (CBS) om het percentage
studenten per herkomstland te meten gedurende het gehele controleproces. Publiek
toegankelijk data – zoals migratiestatistieken per postcodegebied of de gemiddelde
afstand die bepaalde demografische groepen tot hun ouder(s) wonen – is volgens Stichting
Algorithm Audit te onnauwkeurig om voor dit gevoelige onderzoek te gebruiken.
Het is wat Stichting Algorithm Audit dan ook te vroeg om te kunnen concluderen
of studenten met een migratieachtergrond inderdaad benadeeld zijn, al is van
het tegendeel in het onderzoek ook niet gebleken. Stichting Algorithm Audit stelt
wel vast dat er niet is gebleken van directe discriminatie op basis van
migratieachtergrond in het algoritme.

De uitkomsten van de onderzoeken worden gebruikt om te
bepalen of risicoprofilering in de toekomst verantwoord kan worden ingezet om
misbruik met de uitwonendenbeurs op te sporen. Dit is relevant aangezien de
uitwonendenbeurs sinds dit studiejaar is geherintroduceerd voor studenten die
op kamers wonen en een hogere beroepsopleiding of wetenschappelijke opleiding
volgen. DUO en Stichting Algorithm Audit blijven in 2024 samenwerken om de
resultaten van de onderzoeken samen met verschillende maatschappelijke belanghebbenden
te interpreteren. Momenteel selecteert DUO studenten alleen willekeurig voor
controle.

Het volledige rapport *Vooringenomenheid voorkomen* (AA:2024:01) kan [hier](/nl/algoprudence/cases/vooringenomenheid-voorkomen/) worden gevonden.

01-03-2024

{{< accordion_item_close >}}

{{< accordion_item_open title="Onafhankelijke commissie publiceert advies aan gemeenten voor risicoprofilering in de bijstand" id="Rotterdam" background_color="#ffffff" date="29-11-2023" image="/images/logo/logo.svg" tag1="gemeente Rotterdam" tag2="algoprudentie" tag3="machine learning" >}}

**DEN HAAG – Staatssecretaris Alexandra van Huffelen heeft op 29 november het [adviesrapport](/algoprudence/cases/risk-profiling-for-social-welfare-reexamination-aa202302/) aangenomen met daarin concrete normen voor de verantwoorde inzet van algoritmes. Stichting Algorithm Audit stelde een onafhankelijke commissie samen van experts die advies uitbrengt om oneerlijke behandeling te voorkomen bij bijstandsheronderzoek. De aanleiding voor het opstellen van het advies is het controversiële risicomodel dat gebruikt is door de Gemeente Rotterdam tot 2021.**

Wanneer de gemeente onderzoekt of bijstandsgerechtigden nog wel recht hebben op bijstand wordt soms gebruik gemaakt van algoritmische profilering. Het adviesrapport, opgesteld door vertegenwoordigers van de Ombudsman van Amsterdam en Rotterdam, verschillende academici, en een wethouder uit Tilburg, adviseert dat onder andere postcode, het aantal kinderen en laaggeletterdheid niet meer als kenmerk gebruikt mag worden voor profilering. Eerder is gebleken dat profilering in de context van de bijstand kan leiden tot discriminatie. De onafhankelijke commissie stelt dat er ook andere ethische bezwaren kleven aan algoritmische profilering. Sommige zelflerende algoritmes zijn namelijk te ingewikkeld om de beslissingen nog goed aan de burger te kunnen uitleggen. De commissie adviseert daarom om bepaalde algoritmes niet meer te gebruiken.

Het advies is gericht aan alle 340 Nederlandse gemeenten. Het advies vormt een onderdeel van de ‘algoprudentie’ die Stichting Algorithm Audit ontwikkelt om samen met experts en diverse belangengroepen tot concrete normen te komen voor de verantwoorde inzet van algoritmes. Stichting Algorithm Audit is een onafhankelijk kennisplatform voor ethische algoritmes en AI en wordt ondersteund door het European AI\&Society Fund, het SIDN fonds en het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties.

{{< image id="presentatie" width_desktop="6" width_mobile="12" image1="/images/algoprudence/AA202302/Algorithm audit presentatie BZK FB-18.jpg" alt1="Presentatie Staatssecretaris voor Digitalisering" caption1="Presentatie Staatssecretaris voor Digitalisering" >}}

29-11-2023

{{< container_close >}}
