---
title: >-
  Bias assessment report Short Stay Visum – SigmaRed for the Dutch Ministry of
  Ministry of Foreign Affairs 
subtitle: >
  Bias assessment of Dutch Ministry of Ministry of Foreign Affairs' short stay
  visa classification model by SigmaRed Technologies. The report concludes there
  is no disproportionate discrimination based on age marital status or gender.
  However, we note that essential validation criteria are lacking in the report,
  which are essential to support these conclusions.
image: /images/knowledge_base/BuZa_SR.png
author: SigmaRed
type: regular
summary: >-
  Bias assessment of Dutch Ministry of Ministry of Foreign Affairs' short stay
  visa classification model by SigmaRed Technologies
---

Full report: [https://www.tweedekamer.nl/kamerstukken/detail?id=2024D17777\&did=2024D17777](https://www.tweedekamer.nl/kamerstukken/detail?id=2024D17777\&did=2024D17777)

#### Bias assessment report Short Stay Visum – SigmaRed for the Dutch Ministry of Ministry of Foreign Affairs

Bias assessment report requested by the Dutch Ministry of Ministry of Foreign Affairs on the application process for short-stay visas (known as Kort Verblijf Visum, or KVV), which makes use of a rule-based classification model to categorise applicants into a fast, regular or intensive track. The goal of the study is to "detect and assess potential inter-group bias by examining the relationship between risk profile percentages and rejection rates across different demographic groups".

Based on a comparative analysis of disparate impact ratios between 2022 and 2023, it is concluded that "no disproportionate discrimination based on age marital status or gender" is found\*. In the report, the rationale for excluding many bias metrics is provided. However, this explanation is absent for conditional demographic parity (CDP). Despite the common <a href="https://arxiv.org/abs/2005.05906" target="_blank">understanding</a> that CDP is suggested as an alternative to DI to mitigate Simpson's paradox, the authors do not clarify why DI is favored over CDP. Using CDP as a bias metric may result in different quantitative outcomes that might fail to support the current conclusion of the report.

Moreover, the bias assessment does not evaluate the eligibility of the selection criteria used in the assessed risk profile. The following 7 criteria are used in the model:

1. Purpose of stay
2. Location of application
3. Nationality
4. Gender
5. Age class
6. Marital status
7. Professional.

Before such selection criteria can be included in a risk profile, it is imperative to justify why differentiation based on these criteria is essential, proportionate and necessary. <a href="https://publicaties.mensenrechten.nl/publicatie/61a734e65d726f72c45f9dce" target="_blank">Guidelines</a> from the Netherlands Institute on Human Rights outline this obligation. For instance, quantitative evidence supporting the inclusion of selection criteria in a risk profile could be obtained through hypothesis testing on random samples of visa applicants. It is unclear why this obvious first step in assessing bias in risk profiling is absent in the report.

In the context of differentiation on the basis of age, the Netherlands Institute on Human Rights explains:

> "It is not necessarily prohibited for an algorithm to consider someone’s age. However, there must be a clear connection between age and the aim pursued. Until it is shown that someone’s age increases the likelihood \[of a rejected visum application], age is ineligible as a selection criteria in algorithmic-driven selection procedures."

So, it's remarkable that the assessment solely focusses on the quantitative aspects of bias and fairness and concludes no age discrimination occurs.

In general, the socio-technological nature of algorithmic-driven decision-making processes is overlooked in this bias assessment. It is crucial to recognise that mitigating algorithmic bias requires attention of both the quantitative and qualitative reasoning paradigm, not only including numbers but also fostering organisational checks and balances, and a safe working environment that promotes open discussion about data-driven decision-making.

Lastly, instead of using advanced causal inference techniques such as inverse probability weighting (IPW) and instrument variable (IV) analysis to assess whether the rule-based classification model had a direct effect on the decisions made by officers, a preference is given to the simpler F-test.

\* for visa applicants with the Yemeni nationality a certain degree of unequal treatment is reported	&#x9;
