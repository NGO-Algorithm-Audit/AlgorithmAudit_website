---
layout: article
featured: true
type: knowledgebase_item
author: Algorithm Audit
summary: >-
  Step-by-step guide to prevent automated decision-making based solely on profiling
facets:
  - value: type_standard
    label: standard
weight: -15
title: >-
  Public standard 'Meaningful human intervention for risk profiling algorithms'
subtitle: >
  Step-by-step guide to prevent automated decision-making based solely on profiling
image: /images/knowledge_base/Public_standard_meaningful_human_intervention.png
---

### Public standard
How to prevent fully automated decision, as prohibited under art. 22 of the GDPR, when using risk profiling algorithms? Algorithm Audit has brought together a pragmatic step-by-step guide on how to navigate this prohibition. We read many and often lengthy documents that have been published in the aftermath of the ground breaking Schufa-ruling by the Court of Justice of the EU. Based on these insights, combined with our practical experience on human-algorithm interaction, the public standard also provides concrete guidelines how to comply with article 14 of the AI Act (human oversight).

Note: over the coming months, this public standard will be integrated into Q7 of our open-source [AI Act Implementation Tool](/technical-tools/implementation-tool/).

{{< embed_pdf url="/pdf-files/knowledge-base/20250515 Public standard Meaningful human intervention.pdf" url2="/pdf-files/knowledge-base/20250515 Carrousel Meaningful human intervention risk profiling algorithms.pdf" width_mobile_pdf="12" width_desktop_pdf="6" >}}