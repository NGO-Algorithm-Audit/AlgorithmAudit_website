---
icon: fas fa-search
featured: false
layout: article
type: knowledgebase_item
author: Algorithm Audit
facets:
  - value: type_white_paper
    label: white paper
  - value: subject_FR
    label: fundamental rights
summary: Comparative review of 10 FRIAs
weight: -11
title: Comparative review of 10 FRIAs
subtitle: |
  Comparative review of 10 FRIAs
image: /images/knowledge_base/Comparative_review_10_FRIAs.png
---

### Comparative review of 10 FRIAs

We have conducted a comparative review of 10 existing FRIAs frameworks, evaluating them against 12 requirements across legal, organizational, technical and social dimensions.

Our assessment shows a sharp divide regarding the length and completeness of FRIAs, for instance:

ü©∫ Many FRIAs have not incorporated legal instruments that address the core of normative decision-making, such as the objective justification test, which is particularly important when users are segmented by an AI system.

üî¢ None of the FRIAs connect accuracy metrics to assessing the conceptual soundness of an AI-systems‚Äô statistical methodology, such as (hyper)parameter sensitivity testing for ML and DL methods, or statistical hypothesis testing for risk assessment methods.

ü´¥üèΩ Besides, the technocratic approach taken by most FRIAs does not empower citizens to meaningfully participate in shaping the technologies that govern them. Stakeholder groups should be more involved in the normative decision that underpin data modelling.

Are you a frequent user, or a developer of a FRIA, please reach out to [info@algorithmaudit.eu](mailto:info@algorithmaudit.eu) to share insights based on our case-based AI auditing experience.

{{< embed_pdf url="/pdf-files/knowledge-base/20240918_Comparative review 10 FRIAs Algorithm Audit.pdf" width_mobile_pdf="12" width_desktop_pdf="6" >}}