---
summary: >-
  Based on bias testing results from the Municipality of Amsterdam, it is argued
  that that algorithms can play an important role in mitigating biases
  originating from humans
layout: article
type: knowledgebase_item
author: "Jurriaan Parie, Vardâyani Djwalapersad"
title: Algorithm Audit (op-ed) – Human vs machine bias
facets:
  - value: type_op_ed
    label: op-ed
  - value: none
    label: Parool
weight: -3
subtitle: ""
image: /images/knowledge_base/Op-ed-3.png
---

Op-ed, as <a href="https://www.parool.nl/columns-opinie/opinie-onderzoek-vooringenomenheid-van-zowel-algoritme-als-ambtenaar~bd69aa5e/" target="_blank">published</a> in Parool on 14-02-2024, arguing that:

- Not only algorithmic-driven processes can have discriminatory effects, but that human-driven process can be severely biased too;
- They argue therefore that, as a result of the performed bias test by the City of Amsterdam, not only should the explainable boosting ML-model be abandoned, but also the allegedly detected human biases within the processes of the City of Amsterdam should be subject to further investigation;
- Because more open and transparent research is needed to strengthen human-machine interplay to prevent systemic biases in the digital future.

{{< embed_pdf url="/pdf-files/knowledge-base/20240214_Human-vs-machine-bias.pdf" width_mobile_pdf="12" width_desktop_pdf="6" >}}