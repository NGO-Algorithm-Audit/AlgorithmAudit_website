---
title: Standards for AI
subtitle: >
  Responsible AI involves ethical considerations and trade-offs, these cannot be
  solved by technical standards only, but must involve collective deliberation
  by all stakeholders. Through national and European standardization bodies, we
  participate in discussions on the bandwidth of technical and normative AI
  standards
image: /images/svg-illustrations/case_repository.svg
team:
  title: AI Act standardization team
  icon: fas fa-user-friends
  button_text: Other teams
  id: team
  button_link: /about/teams/
  team_members:
    - image: /images/people/ALeoneDeCastris.jpg
      name: Arcangelo Leone de Castris
      bio: |
        AI Policy Researcher at The Alan Turing Institute, London
    - image: /images/people/EPetersen.jpeg
      name: Eike Petersen
      bio: |
        Senior Scientist Medical AI, Fraunhofer MEVIS, Hannover
    - image: /images/people/IMastenbroek.jpg
      name: Irma Mastenbroek
      bio: |
        Independent AI ethicist and freelance mathematician, Berlin
    - image: /images/people/SDas.jpg
      name: Sneha Das
      bio: |
        Assistant Professor Technical University of Denmark, Copenhagen
---

{{< container_open icon="fas fa-check" title="AI Act standardization request" id="standardization-request" >}}

In 2023, European standardization bodies CEN and CENELEC have accepted a standardization request on Artificial Intelligence from the European Commission. Joint Technical Committee 21 (JTC21) of CEN-CLC is currently developing European standards which, in the future, would be able to provide manufacturers the presumption of conformity with the upcoming AI Act. As a member of Dutch standardization body NEN, Algorithm Audit contributes to the European debate how fundamental rights should be co-regulated by product safety. We do this by participating in the following working groups of JTC21:

* WG2 – Risk management systems
* WG3 – Engineering aspects
* WG4 – Trustworthiness framework.

During last JTC21's plenary meeting in Dublin 12-14 Feb in Dublin, Algorithm Audit presented below slides on Fundamental Rights Impact Assessments (FRIAs) and the need for inclusive, deliberative stakeholder panels to deploy responsible AI.

{{< image id="CEN-logo" width_desktop="3" width_mobile="6" image1="/images/partners/NEN.svg" alt1="Stichting Koninklijk Nederlands Normalisatie Instituut" caption1="Stichting Koninklijk Nederlands Normalisatie Instituut" image2="/images/partners/CEN.jpg" alt2="European Committee for Standardization" caption2="European Committee for Standardization" >}}

{{< pdf_frame articleUrl1="https://drive.google.com/file/d/1vadydN4_ZEXJ0h_Sj-4GRUwJSacM0fCK/preview" width_desktop_pdf="12" width_mobile_pdf="12" >}}

{{< container_close >}}

{{< container_open title="Standards" id="AI-standards" icon="fas fa-ruler" >}}

The standardization request of the European Commission, that will provide a presumption of conformity with the AI Act, relates to ten aspects:

1. Risk management systems for AI systems
2. Governance and quality of datasets used to build AI systems
3. Record keeping through logging capabilities by AI systems
4. Transparency and information provisions for users of AI systems
5. Human oversight of AI systems
6. Accuracy specifications for AI systems
7. Robustness specifications for AI systems
8. Cybersecurity specifications for AI systems
9. Quality management systems for providers of AI systems, including post-market monitoring processes
10. Conformity assessment for AI systems.

In our audits, Algorithm Audit incorporates all of the above aspects, except 8. Cybersecurity specifications for AI systems. Organisations can learn from our technical and normative audits reports that are made [publicly available](/algoprudence/). The full standardisation request of the European Commission can be found [here](https://single-market-economy.ec.europa.eu/single-market/european-standards/standardisation-requests_en).

{{< button button_text="Collaborate with us" button_link="/knowledge-platform/collaboration/" >}}

{{< container_close >}}

{{< team >}}
