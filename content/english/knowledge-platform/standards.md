---
title: Standards for AI
subtitle: >
  Responsible AI involves ethical considerations and trade-offs, these cannot be
  solved by technical standards only, but must involve collective deliberation
  by all stakeholders. Through national and European standardization bodies, we
  participate in discussions on the bandwidth of technical and normative AI
  standards
image: /images/svg-illustrations/case_repository.svg
text_field1:
  title: AI Act standards
  icon: fas fa-check
  id: info
  content: |
    AI Act standards
team:
  title: AI standards team
  icon: fas fa-user-friends
  button_text: Other teams
  id: team
  button_link: /about
  team_members:
    - image: /images/people/EPetersen.jpeg
      name: Eike Petersen
      bio: |
        Post-doc Fair AI in Medicine, Technical University of Denmark
    - image: /images/people/JParie.jpg
      name: Jurriaan Parie
      bio: |
        Director and board member
form:
  title: AI Standards cohort application form
  button_text: Apply
  backend_link: ...
  id: form
  questions:
    - label: Name
      id: name
      type: text
    - label: Mail address
      id: mail
      type: email
      placeholder: Mail address
---

{{< container_open icon="fas fa-check" title="AI Act standardization request" id="standardization-request" >}}

In 2023, European standardization bodies CEN and CENELEC have accepted a standardization request on Artificial Intelligence from the European Commission. Joint Technical Committee 21 (JTC21) of CEN-CLC is currently developing European standards which, in the future, would be able to provide manufacturers the presumption of conformity with the upcoming AI Act. As a member of Dutch standardization body NEN, Algorithm Audit contributes to the European debate how fundamental rights should be co-regulated by product safety. We do this by participating in the following working groups of JTC21:

* WG2 – Risk management systems
* WG3 – Engineering aspects
* WG4 – Trustworthiness framework.

During last JTC21's plenary meeting in Dublin 12-14 Feb in Dublin, Algorithm Audit presented below slides on Fundamental Rights Impact Assessments (FRIAs) and the need for inclusive, deliberative stakeholder panels to deploy responsible AI.

{{< image image="/images/partners/NEN.svg" alt="Nederlands Normalisatie Instituut " caption="Nederlands Normalisatie Instituut " width="12" >}}

{{< pdf_frame articleUrl="/pdf-files/20240213_JTC21_plenary_FRIAs_stakeholder_panels.pdf" width="100%" >}}

{{< container_close >}}

{{< container_open title="Standards" id="AI-standards" icon="fas fa-ruler" >}}

The standardization request of the European Commission, that will provide a presumption of conformity with the AI Act, relates to ten aspects:

1. Risk management systems for AI systems
2. Governance and quality of datasets used to build AI systems
3. Record keeping through logging capabilities by AI systems
4. Transparency and information provisions for users of AI systems
5. Human oversight of AI systems
6. Accuracy specifications for AI systems
7. Robustness specifications for AI systems
8. Cybersecurity specifications for AI systems
9. Quality management systems for providers of AI systems, including post-market monitoring processes
10. Conformity assessment for AI systems.

The full standardisation request can be found [here](https://single-market-economy.ec.europa.eu/single-market/european-standards/standardisation-requests_en).

In our audits, Algorithm Audit pays incorporates all of the above aspects except 8. Cybersecurity specifications for AI systems. Do you want to learn more about our collaborative efforts?

{{< button button_text="Discuss collaboration" button_link="/knowledge-platform/collaboration/" >}}

{{< container_close >}}

{{< team >}}
