---
title: AI standards
subtitle: >
  Responsible AI involves ethical considerations and trade-offs, these cannot be
  solved by technical standards only, but must involve collective deliberation
  by all stakeholders. Through national and European standardization bodies, we
  participate in discussions on the bandwidth of technical and normative AI
  standards
image: /images/svg-illustrations/case_repository.svg
text_field1:
  title: AI Act standards
  icon: fas fa-check
  id: info
  content: |
    AI Act standards
team:
  title: AI Standards Team
  icon: fas fa-user-friends
  button_text: Other teams
  id: team
  button_link: /about
  team_members:
    - image: /images/people/EPetersen.jpeg
      name: Eike Petersen
      bio: |
        Post-doc Fair AI in Medicine, Technical University of Denmark
    - image: /images/people/JParie.jpg
      name: Jurriaan Parie
      bio: |
        Director and board member
form:
  title: AI Standards cohort application form
  button_text: Apply
  backend_link: ...
  id: form
  questions:
    - label: Name
      id: name
      type: text
    - label: Mail address
      id: mail
      type: email
      placeholder: Mail address
---

{{< container_open icon="fas fa-check" title="AI Act standards" id="ai-act" >}}

In 2023, European standardization bodies CEN and CENELEC have accepted a standardization request on Artificial Intelligence from the European Commission. Joint Technical Committee 21 (JTC21) of CEN-CLC is currently developing European standards which, in the future, would be able to provide manufacturers the presumption of conformity with the upcoming AI Act. As a member of Dutch standardization body NEN, Algorithm Audit contributes to the European debate how fundamental rights should be co-regulated by product safety. We do this by participating in the following working groups of JTC21:

* WG2 – Risk management systems
* WG3 – Engineering aspects
* WG4 – Trustworthiness framework.

During last JTC21's plenary meeting in Dublin 12-14 Feb in Dublin, Algorithm Audit presented below slides on Fundamental Rights Impact Assessments (FRIAs) and the need for inclusive, deliberative stakeholder panels to deploy responsible AI.

{{< pdf_frame articleUrl="/pdf-files/20240213_JTC21_plenary_FRIAs_stakeholder_panels.pdf" width="100%" >}}

{{< container_close >}}

{{< team >}}
