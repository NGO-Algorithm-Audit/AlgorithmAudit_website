---
title: Vacancies
subtitle: |
  Find here an overview of current job openings at Algorithm Audit
image: /images/svg-illustrations/about.svg
form:
  title: Hi
  content: Apply here for this position
  button_text: Submit
  backend_link: 'https://formspree.io/f/mdoqdpnn'
  id: standardization-cohort-form
  questions:
    - label: Name
      id: name
      required: true
      type: text
    - label: WG2
      id: WG
      value: WG2
      required: false
      type: checkbox
    - label: WG3
      id: wg3
      value: WG3
      type: checkbox
    - label: WG4
      id: wg4
      value: WG4
      type: checkbox
    - label: File
      id: file
      required: true
      file_type: '.docx, .pdf'
      type: file
---

{{< accordions_area_open >}}

{{< accordion_item_open image="/images/logo/logo.svg" title="FairAI expert – AI Act standardization cohort" id="standardization" tag1="rolling applications" tag2="2-4 hours per week" tag3="voluntary" background_color="#ffffff" >}}

{{< button button_text="Apply for this function" button_link="#standardization-cohort-form" >}}

#### Summary

Would you like to contribute to shaping AI standards for the common good? Become
part of Algorithm Audit’s part-time cohort, consisting of 5 international qualitative
and quantitative responsible AI experts. By joining, you will be registered on
behalf of Algorithm Audit as a CEN-CENELEC JTC21 expert, granting you direct
involvement in working groups devising AI standards at the European level. Participating
in this cohort positions you to become an AI Act expert towards the
implementation of the Act in 2026. Besides, it enables you to work together
with cutting-edge not-for-profit international AI auditing experts.

#### What is Algorithm Audit?

Algorithm Audit is a European knowledge platform for
AI bias testing and normative AI standards. We are a young, tech-savvy NGO working
on ethical issues that arise in real-world algorithms. We bring together
experts from various professional backgrounds to build bottom-up public
knowledge how to use AI in a responsible manner (see our case repository: https://algorithmaudit.eu/algoprudence/).
Besides, we develop, maintain and test open-source AI auditing tools. Check for
instance our synthetic data generation and bias detection tool cohorts (https://algorithmaudit.eu/about/teams/).

#### &#xA;Project activities

You will follow standardization activities in one of
the following working groups (WGs): WG2 Operational aspects (e.g., risk
management), WG3 Engineering aspects (e.g., data and bias) or WG4 Trustworthiness
(e.g., fundamental rights). Within your chosen WG, your role involves staying
informed about ongoing standardization activities by reviewing online materials
and attending WG meetings. Depending on the distribution of cohort members over
the WGs, tasks can be divided. During the first 4 weeks of the cohort, you will
undergo together with fellow cohort members a concise online standardization training
to familiarize yourselves with using CEN-CENELEC’s information system. After
this, you will collaborate with Algorithm Audit’s AI auditing experts to
formulate written contributions for ongoing standardization activities. Insights
gained from Algorithm Audit’s bottom-up auditing work will serve as input for top-down
AI standards currently under development. Every 4-6 weeks, you will provide a brief
summary of the WG’s recent progress to your fellow cohort members.

#### &#xA;&#xA;What will you do as cohort team member?   

* Dedicate 2-4 hours per week from Apr-15 up to Dec-31st
  2024 on JTC21 standardization activities;
* Translate bottom-up AI auditing experiences into
  meaningful contributions to procedural and technical standards for AI, for instance
  hypothesis testing standards for risk profiling algorithms, inclusion of
  stakeholder panels for qualitative interpretation of confusion matrix-based
  performance/fairness metrics and your own ideas;
* Coordinate your own work activities. Reading
  activities can be scheduled at your convenience. Attendance at working group
  meetings may necessitate some planning;
* Share (bi)monthly updates with Algorithm Audit’s standardization
  cohort;
* Become an expert in standards that will underpin the
  AI Act from 2026 onwards.

  Candidate profile
* PhD-candidate or MSc degree in one of the following
  fields related to responsible AI: computer science, engineering, statistics,
  mathematics, ethics, philosophy, law, policy or social sciences with focus on digital society;      
  Proven academic track record and/or contributions
  to public debate on responsible AI;
* Understanding of academic discussions concerning AI and its intersection
  with fundamental rights, explainability, human oversight, and/or risk management;
* Willing to contribute 2-4h per week, besides your day-to-day professional
  job, to build public knowledge for responsible algorithms;
* You can assure there is no conflict of interest
  between contributing to AI standards from a common good-perspective and your professional
  activities. If you are employed in industry, please provide further details on your motivation for
  participating in standardization endeavors and how you plan to address any
  potential conflicts;
* Available up to 31-12-2024 to contribute to participate
  in the cohort;
* Advantageous: Methodological expertise in hypothesis
  testing, unsupervised machine learning (specifically clustering) and
  statistical inference.

#### Our approach to diversity, equity and inclusion

Algorithm Audit’s commitment is reflected in
its core mission to strengthen the fairness and non-discriminatory deployment
of AI in all parts of society. We build and share public knowledge about
discriminatory bias and fostering equitable algorithms and methods for
data-analysis. In all our work special attention is paid to the inclusion of
various ethnic and gender backgrounds.

{{< form1 >}}

{{< accordion_item_close >}}

{{< accordions_area_close >}}
